{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfjQl01A0R0LlK+IMeqS3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaboraDev/hackathon_one_flightOnTime/blob/main/DOC_DS5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relatório de Arquitetura de Pipeline e Script - Semana 05 (DS5)\n",
        "\n",
        "**Detalhes do Projeto**\n",
        "*   **Responsáveis:** Amélia e Ana, Time DS (Liderança: Helena)\n",
        "*   **Repositório:** [Projeto FlightOnTime](https://github.com/LaboraDev/hackathon_one_flightOnTime/tree/main)\n",
        "*   **Conformidade:** Boas práticas de Engenharia de Software aplicadas a Data Science.\n",
        "*   **Script Rastreável:** [flight_delay_pipeline.py](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py)\n",
        "*   **Notebook Rastreável:** [Consolidado_S03_splitTemporal.ipynb](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/Consolidado_S03_splitTemporal.ipynb)\n",
        "*   **Eficiência Técnica:** Arquitetura modular com separação clara entre lógica de negócio e experimentação.\n",
        "*   **Status:** Finalizado | **Data:** 17/01/2026\n",
        "\n",
        "***\n",
        "\n",
        "## 1. Visão Geral\n",
        "\n",
        "Durante a Semana 05, consolidamos a [arquitetura do projeto](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py) através da modularização do código em um script Python reutilizável. O objetivo foi transformar o projeto de um notebook isolado em um **sistema integrado e reprodutível**, separando a lógica de processamento (script) da experimentação e análise (notebook). Este trabalho garante que todas as transformações aplicadas aos dados sejam consistentes, rastreáveis e prontas para integração com APIs de produção no projeto [FlightOnTime](https://github.com/LaboraDev/hackathon_one_flightOnTime/tree/main).\n",
        "\n",
        "***\n",
        "\n",
        "## 2. Dicionário de Terminologia Técnica\n",
        "Para garantir a compreensão de todos, usamos as seguintes definições:\n",
        "- **Pipeline:** Sequência automatizada de transformações aplicadas aos dados desde a ingestão até o modelo final.\n",
        "- **Script Python:** Arquivo `.py` que centraliza funções reutilizáveis, separado do notebook de experimentação. [flight_delay_pipeline.py](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py)\n",
        "- **Modularização:** Técnica de dividir código em componentes independentes e reutilizáveis.\n",
        "- **Transformer (sklearn):** Classe que implementa métodos `fit()` e `transform()` para processamento de dados.\n",
        "- **Reprodutibilidade:** Capacidade de obter os mesmos resultados executando o mesmo código em momentos diferentes.\n",
        "- **API (Application Programming Interface):** Interface que permite integração do modelo com sistemas externos.\n",
        "\n",
        "***\n",
        "\n",
        "## 3. Blocos Funcionais do Script\n",
        "O script [`flight_delay_pipeline.py`](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py) organiza o código em cinco famílias principais de funções.\n",
        "\n",
        "| Bloco Funcional | Propósito | Principais Componentes |\n",
        "| :--- | :--- | :--- |\n",
        "| **Ingestão e Limpeza** | Carregar e padronizar dados brutos da ANAC. | `carregar_dataset_base()`, `renomear_colunas()` |\n",
        "| **Feature Engineering** | Criar variáveis preditivas a partir dos dados brutos. | `DatasFeaturesTransformer`, `UltimateFeatureEngineer`, `MediaAtrasoTransformer` |\n",
        "| **Divisão de Dados** | Separar dados respeitando ordem cronológica. | `criar_split_temporal_train_val_test()` |\n",
        "| **Modelagem** | Treinar e avaliar modelos de ML. | `treinar_classificador()`, `montar_preprocessador()` |\n",
        "| **Explicabilidade** | Interpretar decisões do modelo. | `explicar_global_xgb()`, `explicar_local_xgb()` |\n",
        "\n",
        "***\n",
        "\n",
        "## 4. Funil de Utilização ([Notebook](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/Consolidado_S03_splitTemporal.ipynb) → [Script](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py))\n",
        "\n",
        "### 4.1 Como o Notebook Consome o Script\n",
        "| Etapa no Notebook | Função do Script Utilizada | Célula | Descrição |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Importação** | `import flight_delay_pipeline as scr` | [1] | Carrega todas as funções do módulo. |\n",
        "| **Carregamento de Dados** | `scr.carregar_dataset_base()` | [3] | Lê e concatena 54 arquivos CSV da ANAC. |\n",
        "| **Análise Exploratória** | `scr.eda_viz()` | [4] | Gera visualizações automáticas do dataset. |\n",
        "| **Criação do Target** | `scr.criar_target_atrasado()` | [6] | Aplica regra D15 para rotular voos. |\n",
        "| **Split Temporal** | `scr.criar_split_temporal_train_val_test()` | [9] | Divide dados cronologicamente. |\n",
        "| **Treinamento** | `scr.treinar_classificador()` | [15] | Executa pipeline completo de ML. |\n",
        "| **Explicabilidade** | `scr.explicar_global_xgb()` | [28] | Extrai importância de variáveis. |\n",
        "\n",
        "### 4.2 Benefícios da Separação\n",
        "| Dimensão | Score | Observação Técnica |\n",
        "| :--- | :--- | :--- |\n",
        "| **Reprodutibilidade** | 10/10 | Mesma função sempre produz mesmo resultado. |\n",
        "| **Manutenção** | 10/10 | Correções no script refletem em todos os notebooks. |\n",
        "| **Testabilidade** | 9/10 | Funções isoladas podem ser testadas individualmente. |\n",
        "| **Legibilidade** | 10/10 | Notebook fica focado em análise, não em implementação. |\n",
        "\n",
        "***\n",
        "\n",
        "## 5. Regras e decisões do projeto\n",
        "Estabelecemos os seguintes pontos fundamentais para a arquitetura do pipeline:\n",
        "\n",
        "*   **Separação de Responsabilidades:** O notebook executa análises e toma decisões; o script implementa a lógica de transformação. Essa separação evita duplicação de código e facilita manutenção.\n",
        "*   **Transformers Personalizados:** Criamos classes que herdam de `BaseEstimator` e `TransformerMixin` do sklearn, garantindo compatibilidade com `Pipeline` e `ColumnTransformer`. **[DatasFeaturesTransformer](attached_file:1)**\n",
        "*   **Configuração Centralizada:** Constantes como `TARGET_COL`, `DEFAULT_RENAME_MAP` e `DATETIME_COLS` estão definidas no topo do script, facilitando ajustes futuros.\n",
        "*   **Funções de Alto Nível:** `treinar_classificador()` encapsula todo o fluxo de treino (feature engineering → pré-processamento → modelo), permitindo chamadas simples no notebook.\n",
        "*   **Preparação para API:** Funções como `salvar_pickle()` e `carregar_pickle()` preparam o terreno para integração com FastAPI, onde o modelo treinado será carregado e utilizado em tempo real.\n",
        "\n",
        "***\n",
        "\n",
        "## 6. Respostas às Perguntas-Chave\n",
        "\n",
        "### 6.1 Qual é o papel do script Python no projeto?\n",
        "O script [`flight_delay_pipeline.py`](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py) atua como a **biblioteca central** do projeto, centralizando todas as funções críticas de processamento de dados, engenharia de features e modelagem. Ele transforma o projeto de um notebook isolado em um sistema modular e reutilizável.\n",
        "\n",
        "### 6.2 Por que separar lógica em um script externo?\n",
        "A separação traz três benefícios principais:\n",
        "1. **Reutilização:** A mesma função pode ser usada em múltiplos notebooks ou na API sem duplicar código.\n",
        "2. **Manutenção:** Correções de bugs ou melhorias são feitas uma vez e refletem em todo o projeto.\n",
        "3. **Clareza:** O notebook fica focado em análise e visualização, não em detalhes de implementação.\n",
        "\n",
        "### 6.3 Quais tipos de funções o script centraliza?\n",
        "O script agrupa cinco categorias:\n",
        "- **Utilitárias:** Carregamento de dados, renomeação de colunas, salvamento de objetos.\n",
        "- **Transformers:** Classes customizadas para feature engineering (`DatasFeaturesTransformer`, `MediaAtrasoTransformer`).\n",
        "- **Pipeline:** Funções que montam e executam pipelines completos (`treinar_classificador`, `montar_preprocessador`).\n",
        "- **Avaliação:** Extração de métricas e criação de relatórios (`extrair_metricas`).\n",
        "- **Explicabilidade:** Interpretação de modelos XGBoost (`explicar_global_xgb`, `explicar_local_xgb`).\n",
        "\n",
        "### 6.4 Como o script ajuda na organização do pipeline?\n",
        "Ele estabelece uma **hierarquia clara de responsabilidades**:\n",
        "```\n",
        "Notebook (Análise) → Script (Lógica) → Dados/Modelo\n",
        "```\n",
        "Cada etapa do pipeline (ingestão → feature engineering → treino → avaliação) possui funções dedicadas no script, eliminando código duplicado e tornando o fluxo explícito.\n",
        "\n",
        "### 6.5 Como ele contribui para reprodutibilidade?\n",
        "Todos os parâmetros críticos (seed aleatório, colunas a remover, configuração de features) estão centralizados no script. Executar `scr.treinar_classificador()` com os mesmos dados **sempre** produz o mesmo modelo, independente de quem execute ou quando.\n",
        "\n",
        "### 6.6 Como o notebook utiliza esse script?\n",
        "O notebook importa o script na [célula 1](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/Consolidado_S03_splitTemporal.ipynb) e faz chamadas diretas:\n",
        "```python\n",
        "import flight_delay_pipeline as scr\n",
        "\n",
        "df = scr.carregar_dataset_base(pasta='./dados_vra/dados_vra')\n",
        "df_model = scr.criar_target_atrasado(df, limite_min=15)\n",
        "```\n",
        "Isso mantém o notebook **enxuto** (focado em decisões) e o script **denso** (focado em execução).\n",
        "\n",
        "### 6.7 O que o script não faz (limitações)?\n",
        "Atualmente, o script:\n",
        "- **Não gerencia configurações externas:** Parâmetros estão hardcoded; ideal seria usar arquivos `.yaml` ou `.json`.\n",
        "- **Não possui testes automatizados:** Funções críticas deveriam ter testes unitários (`pytest`).\n",
        "- **Não lida com escala:** Dependência de arquivos CSV locais limita processamento de volumes muito grandes.\n",
        "\n",
        "### 6.8 O que poderia ser expandido no futuro?\n",
        "Melhorias arquiteturais planejadas:\n",
        "1. **Configuração Externa:** Migrar constantes para `config.yaml` permitindo ajustes sem alterar código.\n",
        "2. **Logging Estruturado:** Adicionar logs detalhados para rastreamento de execução (`logging` module).\n",
        "3. **Pipeline em Nuvem:** Adaptar funções para rodar em ambientes como Google Cloud Functions ou AWS Lambda.\n",
        "4. **Testes Automatizados:** Criar suite de testes com `pytest` para validar transformações.\n",
        "\n",
        "***\n",
        "\n",
        "## 7. Análise de Riscos Arquiteturais\n",
        "\n",
        "| Risco | Severidade | Mitigation Strategy |\n",
        "| :--- | :--- | :--- |\n",
        "| **Dependências Hardcoded** | Média | Migrar para arquivo de configuração externo. |\n",
        "| **Falta de Testes** | Alta | Implementar testes unitários para funções críticas. |\n",
        "| **Escalabilidade Limitada** | Média | Adaptar para leitura de fontes distribuídas (Parquet/Cloud). |\n",
        "| **Versionamento de Modelos** | Baixa | Implementar MLflow ou similar para tracking. |\n",
        "\n",
        "***\n",
        "\n",
        "## 8. Checklist de Integridade (Selo de Qualidade)\n",
        "- [x] **Modularidade:** Código separado em funções com responsabilidades únicas.\n",
        "- [x] **Reprodutibilidade:** Seeds e parâmetros fixos garantem resultados consistentes.\n",
        "- [x] **Documentação:** Docstrings em funções críticas explicam parâmetros e retorno.\n",
        "- [x] **Rastreabilidade:** Cada função do script é referenciada no notebook.\n",
        "- [x] **Preparação para Produção:** Funções de serialização (pickle) prontas para deploy.\n",
        "\n",
        "***\n",
        "\n",
        "## 9. Blueprint de Rastreabilidade ([Script](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/flight_delay_pipeline.py) → [Notebook](https://github.com/LaboraDev/hackathon_one_flightOnTime/blob/main/notebooks/semana03/Consolidado_S03_splitTemporal.ipynb))\n",
        "Para auditoria técnica, utilize as referências abaixo :\n",
        "\n",
        "| Componente do Script | Uso no Notebook | Células |\n",
        "| :--- | :--- | :--- |\n",
        "| `carregar_dataset_base()` | Carregamento inicial de dados | [97] |\n",
        "| `criar_flags_qualidade_basicas()` | Auditoria de qualidade | [303] |\n",
        "| `criar_target_atrasado()` | Geração da variável alvo | [329] |\n",
        "| `criar_split_temporal_train_val_test()` | Divisão cronológica dos dados | [529] |\n",
        "| `FeatureConfig` (dataclass) | Definição de features para modelagem | [620] |\n",
        "| `treinar_classificador()` | Pipeline completo de treino | [654] |\n",
        "| `DatasFeaturesTransformer` | Criação de features temporais | [684] |\n",
        "| `MediaAtrasoTransformer` | Features agregadas de atraso | [688] |\n",
        "| `salvar_pickle()` | Exportação do modelo final | [876] |\n",
        "| `explicar_global_xgb()` | Importância de variáveis | [968] |\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "## 10. Conclusão\n",
        "\n",
        "### Validação da Semana 05\n",
        "A arquitetura do projeto foi consolidada com sucesso através da modularização:\n",
        "- **Script Python completo** com 800+ linhas organizadas em blocos funcionais.\n",
        "- **Separação clara** entre experimentação (notebook) e lógica (script).\n",
        "- **Preparação para produção** com funções de serialização e estrutura compatível com APIs.\n",
        "\n",
        "***\n",
        "\n",
        "## Referências\n",
        "- Scikit-learn. (2024). Building Pipelines and Custom Transformers. Disponível em: [Scikit-learn](https://scikit-learn.org/)\n",
        "- Python Software Foundation. (2024). Python Modules and Packages. Disponível em: [Módulos Python](https://docs.python.org/3/tutorial/modules.html)\n",
        "- XGBoost Documentation. (2024). Python API Reference. Disponível em: [XGBoost](https://xgboost.readthedocs.io/)\n",
        "- Lei Geral de Proteção de Dados (LGPD). Lei nº 13.709, de 14 de agosto de 2018. Brasil. Disponível em: [LGPD](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm)\n"
      ],
      "metadata": {
        "id": "RhZsqx9Wmhcu"
      }
    }
  ]
}