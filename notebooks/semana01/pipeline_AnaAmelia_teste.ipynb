{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaboraDev/hackathon_one_flightOnTime/blob/main/pipeline_AnaAmelia_teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "SEMANA 2: PIPELINE DE PRÉ-PROCESSAMENTO E FEATURE ENGINEERING\n",
        "================================================================================\n",
        "\n",
        "Responsáveis:\n",
        "- DS1 (Pré-processamento): Ana\n",
        "- DS2 (Feature Engineering): Amélia\n",
        "\n",
        "Data: 23/12/2025\n",
        "\n",
        "Objetivo:\n",
        "Criar pipeline reutilizável que funcione em dois cenários:\n",
        "1. Treinamento: DataFrame completo (milhões de linhas)\n",
        "2. API/Produção: 1 voo por vez (JSON)\n",
        "\n",
        "Problema Identificado na Semana 1:\n",
        "- Features criadas com groupby() não funcionam na API\n",
        "- Transformações precisam estar DENTRO do pipeline\n",
        "\n",
        "Solução:\n",
        "- Custom Transformer para features agregadas (médias)\n",
        "- Pipeline sklearn para normalização e encoding\n",
        "- Funções reutilizáveis para features temporais\n",
        "\n",
        "Entregáveis:\n",
        "- media_transformer_ds2.pkl (DS2)\n",
        "- preprocessor_ds1.pkl (DS1)\n",
        "- documentacao_ds1_ds2.json\n",
        "- Dados processados para DS3 treinar modelo\n",
        "\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SEMANA 2 - DS1 + DS2: PIPELINE UNIFICADO\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "aqan7GKRhLN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ Bibliotecas importadas com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFBkFSwuhNgU",
        "outputId": "3a921e47-06f6-426d-faf8-70b3841ffbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CARREGAR DADOS DA SEMANA 1 (DO DRIVE)\n",
        "# ============================================\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "print(\"Carregando dados do Google Drive...\")\n",
        "\n",
        "file_id = \"1207psedBKvnS0pJkDITroSzPiWrcz0ag\"\n",
        "zip_path = \"dados_vra.zip\"\n",
        "extract_folder = \"dados_vra\"\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(\"Baixando arquivo do Drive...\")\n",
        "    gdown.download(url, zip_path, quiet=False)\n",
        "else:\n",
        "    print(\"Arquivo ZIP ja existe\")\n",
        "\n",
        "if not os.path.exists(extract_folder):\n",
        "    print(\"Extraindo arquivos...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(extract_folder)\n",
        "else:\n",
        "    print(\"Arquivos ja extraidos\")\n",
        "\n",
        "def carregar_vra(pasta, padrao=\"VRA_*.csv\", sep=\";\", encoding=\"latin-1\", skiprows=1):\n",
        "    caminho_busca = os.path.join(pasta, padrao)\n",
        "    arquivos = sorted(glob.glob(caminho_busca))\n",
        "    if not arquivos:\n",
        "        raise FileNotFoundError(f\"Nenhum arquivo encontrado em {caminho_busca}\")\n",
        "    print(f\"{len(arquivos)} arquivos encontrados\")\n",
        "    dfs = []\n",
        "    for arquivo in arquivos:\n",
        "        df_temp = pd.read_csv(arquivo, sep=sep, encoding=encoding, skiprows=skiprows)\n",
        "        dfs.append(df_temp)\n",
        "    df_final = pd.concat(dfs, ignore_index=True)\n",
        "    print(f\"Concatenacao concluida: {df_final.shape}\")\n",
        "    return df_final\n",
        "\n",
        "print(\"\\nCarregando arquivos CSV...\")\n",
        "df = carregar_vra(pasta=\"/content/dados_vra/dados_vra\")\n",
        "\n",
        "print(\"\\nPadronizando nomes das colunas...\")\n",
        "df.columns = [c.encode(\"latin1\").decode(\"utf-8\") for c in df.columns]\n",
        "mapa_colunas = {\n",
        "    \"ICAO Empresa Aérea\": \"empresa_aerea\",\n",
        "    \"Número Voo\": \"numero_voo\",\n",
        "    \"Código Autorização (DI)\": \"codigo_autorizacao_di\",\n",
        "    \"Código Tipo Linha\": \"codigo_tipo_linha\",\n",
        "    \"ICAO Aeródromo Origem\": \"aerodromo_origem\",\n",
        "    \"ICAO Aeródromo Destino\": \"aerodromo_destino\",\n",
        "    \"Partida Prevista\": \"partida_prevista\",\n",
        "    \"Partida Real\": \"partida_real\",\n",
        "    \"Chegada Prevista\": \"chegada_prevista\",\n",
        "    \"Chegada Real\": \"chegada_real\",\n",
        "    \"Situação Voo\": \"situacao_voo\",\n",
        "    \"Código Justificativa\": \"codigo_justificativa\"\n",
        "}\n",
        "df = df.rename(columns=mapa_colunas)\n",
        "\n",
        "print(\"Convertendo datas...\")\n",
        "df[\"partida_prevista\"] = pd.to_datetime(df[\"partida_prevista\"], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')\n",
        "df[\"partida_real\"] = pd.to_datetime(df[\"partida_real\"], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')\n",
        "\n",
        "print(\"Criando flags de qualidade...\")\n",
        "df[\"flag_partida_prevista_ausente\"] = df[\"partida_prevista\"].isna()\n",
        "df[\"flag_partida_real_ausente\"] = df[\"partida_real\"].isna()\n",
        "df[\"flag_aerodromo_origem_ausente\"] = df[\"aerodromo_origem\"].isna()\n",
        "df[\"flag_data_partida_fora_periodo\"] = (\n",
        "    df[\"partida_prevista\"].notna() &\n",
        "    ((df[\"partida_prevista\"].dt.year < 2021) | (df[\"partida_prevista\"].dt.year > 2025))\n",
        ")\n",
        "LIMITE_HORAS = 24\n",
        "delta_h = (df[\"partida_real\"] - df[\"partida_prevista\"]).dt.total_seconds() / 3600\n",
        "df[\"flag_partida_muito_alto\"] = (\n",
        "    df[\"partida_prevista\"].notna() &\n",
        "    df[\"partida_real\"].notna() &\n",
        "    (delta_h.abs() > LIMITE_HORAS)\n",
        ")\n",
        "\n",
        "print(\"Criando variavel alvo...\")\n",
        "def classificar_situacao_partida(minutos):\n",
        "    if minutos < 0:\n",
        "        return \"Antecipado\"\n",
        "    elif minutos <= 15:\n",
        "        return \"Pontual\"\n",
        "    elif minutos <= 60:\n",
        "        return \"Atraso 15-60\"\n",
        "    elif minutos <= 120:\n",
        "        return \"Atraso 60-120\"\n",
        "    elif minutos <= 240:\n",
        "        return \"Atraso 120-240\"\n",
        "    else:\n",
        "        return \"Atraso > 240\"\n",
        "\n",
        "voos_rotulavel = (\n",
        "    ~df[\"flag_partida_prevista_ausente\"] &\n",
        "    ~df[\"flag_partida_real_ausente\"] &\n",
        "    ~df[\"flag_data_partida_fora_periodo\"] &\n",
        "    ~df[\"flag_partida_muito_alto\"]\n",
        ")\n",
        "df[\"atraso_partida_min\"] = ((df[\"partida_real\"] - df[\"partida_prevista\"]).dt.total_seconds() / 60)\n",
        "df[\"situacao_partida\"] = pd.Series(index=df.index, dtype=\"object\")\n",
        "df.loc[voos_rotulavel, \"situacao_partida\"] = df.loc[voos_rotulavel, \"atraso_partida_min\"].apply(classificar_situacao_partida)\n",
        "df = df[df[\"situacao_partida\"].notna()].copy()\n",
        "df['atrasado'] = (df['atraso_partida_min'] > 15).astype(int)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATASET CARREGADO E PROCESSADO COM SUCESSO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Distribuicao: Pontuais={100*(df['atrasado']==0).mean():.1f}%, Atrasados={100*(df['atrasado']==1).mean():.1f}%\")\n",
        "print(f\"\\nColunas disponiveis:\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_43-VynUkomb",
        "outputId": "9601b641-e106-4f60-b7f8-d560795185ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando dados do Google Drive...\n",
            "Arquivo ZIP ja existe\n",
            "Arquivos ja extraidos\n",
            "\n",
            "Carregando arquivos CSV...\n",
            "54 arquivos encontrados\n",
            "Concatenacao concluida: (3968418, 12)\n",
            "\n",
            "Padronizando nomes das colunas...\n",
            "Convertendo datas...\n",
            "Criando flags de qualidade...\n",
            "Criando variavel alvo...\n",
            "\n",
            "================================================================================\n",
            "DATASET CARREGADO E PROCESSADO COM SUCESSO\n",
            "================================================================================\n",
            "Shape: (3642571, 20)\n",
            "Distribuicao: Pontuais=84.0%, Atrasados=16.0%\n",
            "\n",
            "Colunas disponiveis:\n",
            "   1. empresa_aerea\n",
            "   2. numero_voo\n",
            "   3. codigo_autorizacao_di\n",
            "   4. codigo_tipo_linha\n",
            "   5. aerodromo_origem\n",
            "   6. aerodromo_destino\n",
            "   7. partida_prevista\n",
            "   8. partida_real\n",
            "   9. chegada_prevista\n",
            "  10. chegada_real\n",
            "  11. situacao_voo\n",
            "  12. codigo_justificativa\n",
            "  13. flag_partida_prevista_ausente\n",
            "  14. flag_partida_real_ausente\n",
            "  15. flag_aerodromo_origem_ausente\n",
            "  16. flag_data_partida_fora_periodo\n",
            "  17. flag_partida_muito_alto\n",
            "  18. atraso_partida_min\n",
            "  19. situacao_partida\n",
            "  20. atrasado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ANALISE: COLUNAS RELEVANTES PARA O MODELO\n",
        "# ============================================\n",
        "\n",
        "colunas_usar = {\n",
        "    \"empresa_aerea\": \"SIM - Algumas companhias tem mais atrasos historicamente\",\n",
        "    \"aerodromo_origem\": \"SIM - Alguns aeroportos tem mais congestionamento\",\n",
        "    \"aerodromo_destino\": \"SIM - Alguns destinos tem mais problemas operacionais\",\n",
        "    \"codigo_tipo_linha\": \"SIM - Voos internacionais vs domesticos tem padroes diferentes\",\n",
        "    \"partida_prevista\": \"SIM - Usaremos para extrair: hora, dia da semana, mes (features temporais)\"\n",
        "}\n",
        "\n",
        "colunas_nao_usar = {\n",
        "    \"numero_voo\": \"NAO - Identificador unico, causa overfitting\",\n",
        "    \"codigo_autorizacao_di\": \"NAO - Identificador administrativo, sem valor preditivo\",\n",
        "    \"partida_real\": \"NAO - So existe DEPOIS do voo partir (nao temos na predicao)\",\n",
        "    \"chegada_prevista\": \"NAO - Acontece DEPOIS da partida\",\n",
        "    \"chegada_real\": \"NAO - Acontece DEPOIS da partida\",\n",
        "    \"situacao_voo\": \"NAO - So sabemos DEPOIS do voo acontecer\",\n",
        "    \"codigo_justificativa\": \"NAO - 100% nulo (coluna descontinuada pela ANAC)\",\n",
        "    \"flag_partida_prevista_ausente\": \"NAO - Sempre False (ja filtramos na Semana 1)\",\n",
        "    \"flag_partida_real_ausente\": \"NAO - Sempre False (ja filtramos na Semana 1)\",\n",
        "    \"flag_aerodromo_origem_ausente\": \"NAO - Sempre False (ja filtramos na Semana 1)\",\n",
        "    \"flag_data_partida_fora_periodo\": \"NAO - Sempre False (ja filtramos na Semana 1)\",\n",
        "    \"flag_partida_muito_alto\": \"NAO - Sempre False (ja filtramos na Semana 1)\",\n",
        "    \"atraso_partida_min\": \"NAO - So existe DEPOIS do voo partir (target leakage)\",\n",
        "    \"situacao_partida\": \"NAO - So existe DEPOIS do voo partir (target leakage)\"\n",
        "}\n",
        "\n",
        "target_variaveis = {\n",
        "    \"atrasado\": \"TARGET - 0=Pontual, 1=Atrasado (>15 min)\"\n",
        "}\n",
        "\n",
        "print(\"COLUNAS PARA USAR NO MODELO:\")\n",
        "for col, motivo in colunas_usar.items():\n",
        "    print(f\"  {col:25s} -> {motivo}\")\n",
        "\n",
        "print(\"\\nCOLUNAS QUE NAO DEVEM SER USADAS:\")\n",
        "for col, motivo in colunas_nao_usar.items():\n",
        "    print(f\"  {col:35s} -> {motivo}\")\n",
        "\n",
        "print(\"\\nTARGET (Variavel a prever):\")\n",
        "for col, motivo in target_variaveis.items():\n",
        "    print(f\"  {col:25s} -> {motivo}\")\n"
      ],
      "metadata": {
        "id": "o8gKVoAxkoSy",
        "outputId": "159cac07-0db9-4420-dc83-ad982bf59d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COLUNAS PARA USAR NO MODELO:\n",
            "  empresa_aerea             -> SIM - Algumas companhias tem mais atrasos historicamente\n",
            "  aerodromo_origem          -> SIM - Alguns aeroportos tem mais congestionamento\n",
            "  aerodromo_destino         -> SIM - Alguns destinos tem mais problemas operacionais\n",
            "  codigo_tipo_linha         -> SIM - Voos internacionais vs domesticos tem padroes diferentes\n",
            "  partida_prevista          -> SIM - Usaremos para extrair: hora, dia da semana, mes (features temporais)\n",
            "\n",
            "COLUNAS QUE NAO DEVEM SER USADAS:\n",
            "  numero_voo                          -> NAO - Identificador unico, causa overfitting\n",
            "  codigo_autorizacao_di               -> NAO - Identificador administrativo, sem valor preditivo\n",
            "  partida_real                        -> NAO - So existe DEPOIS do voo partir (nao temos na predicao)\n",
            "  chegada_prevista                    -> NAO - Acontece DEPOIS da partida\n",
            "  chegada_real                        -> NAO - Acontece DEPOIS da partida\n",
            "  situacao_voo                        -> NAO - So sabemos DEPOIS do voo acontecer\n",
            "  codigo_justificativa                -> NAO - 100% nulo (coluna descontinuada pela ANAC)\n",
            "  flag_partida_prevista_ausente       -> NAO - Sempre False (ja filtramos na Semana 1)\n",
            "  flag_partida_real_ausente           -> NAO - Sempre False (ja filtramos na Semana 1)\n",
            "  flag_aerodromo_origem_ausente       -> NAO - Sempre False (ja filtramos na Semana 1)\n",
            "  flag_data_partida_fora_periodo      -> NAO - Sempre False (ja filtramos na Semana 1)\n",
            "  flag_partida_muito_alto             -> NAO - Sempre False (ja filtramos na Semana 1)\n",
            "  atraso_partida_min                  -> NAO - So existe DEPOIS do voo partir (target leakage)\n",
            "  situacao_partida                    -> NAO - So existe DEPOIS do voo partir (target leakage)\n",
            "\n",
            "TARGET (Variavel a prever):\n",
            "  atrasado                  -> TARGET - 0=Pontual, 1=Atrasado (>15 min)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# REGRA DE OURO PARA SELECIONAR FEATURES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nREGRA DE OURO:\")\n",
        "print(\"=\"*80)\n",
        "print(\"Pergunta: 'Essa informacao existe ANTES do voo partir?'\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nSIM - Podemos usar:\")\n",
        "print(\"  - empresa_aerea           -> Sabemos qual companhia\")\n",
        "print(\"  - aerodromo_origem        -> Sabemos de onde sai\")\n",
        "print(\"  - aerodromo_destino       -> Sabemos para onde vai\")\n",
        "print(\"  - partida_prevista        -> Sabemos horario programado\")\n",
        "print(\"  - codigo_tipo_linha       -> Sabemos tipo de voo\")\n",
        "\n",
        "print(\"\\nNAO - NAO podemos usar (vazamento de informacao):\")\n",
        "print(\"  - partida_real            -> So sabemos DEPOIS que decolou\")\n",
        "print(\"  - chegada_real            -> So sabemos DEPOIS que pousou\")\n",
        "print(\"  - atraso_partida_min      -> So calculamos DEPOIS da partida\")\n",
        "print(\"  - situacao_partida        -> So sabemos DEPOIS da partida\")\n",
        "print(\"  - situacao_voo            -> So sabemos DEPOIS do voo\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPORTANTE: Usar colunas que so existem DEPOIS causa 'data leakage'\")\n",
        "print(\"O modelo vai ter 100% de acuracia no treino, mas 0% em producao!\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "lYVcV07qnfbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214960fe-54ac-4ca7-85df-ef6eea894c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "REGRA DE OURO:\n",
            "================================================================================\n",
            "Pergunta: 'Essa informacao existe ANTES do voo partir?'\n",
            "================================================================================\n",
            "\n",
            "SIM - Podemos usar:\n",
            "  - empresa_aerea           -> Sabemos qual companhia\n",
            "  - aerodromo_origem        -> Sabemos de onde sai\n",
            "  - aerodromo_destino       -> Sabemos para onde vai\n",
            "  - partida_prevista        -> Sabemos horario programado\n",
            "  - codigo_tipo_linha       -> Sabemos tipo de voo\n",
            "\n",
            "NAO - NAO podemos usar (vazamento de informacao):\n",
            "  - partida_real            -> So sabemos DEPOIS que decolou\n",
            "  - chegada_real            -> So sabemos DEPOIS que pousou\n",
            "  - atraso_partida_min      -> So calculamos DEPOIS da partida\n",
            "  - situacao_partida        -> So sabemos DEPOIS da partida\n",
            "  - situacao_voo            -> So sabemos DEPOIS do voo\n",
            "\n",
            "================================================================================\n",
            "IMPORTANTE: Usar colunas que so existem DEPOIS causa 'data leakage'\n",
            "O modelo vai ter 100% de acuracia no treino, mas 0% em producao!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FEATURES DERIVADAS (CRIADAS PELO PIPELINE)\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nFEATURES DERIVADAS DE 'partida_prevista':\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "features_derivadas = {\n",
        "    \"hora_dia\": \"Hora de 0 a 23 (ex: 14 para voos as 14h)\",\n",
        "    \"dia_semana\": \"0=Segunda, 6=Domingo\",\n",
        "    \"mes_ano\": \"1=Janeiro, 12=Dezembro\",\n",
        "    \"periodo_dia\": \"Manha/Tarde/Noite/Madrugada\",\n",
        "    \"fim_de_semana\": \"1 se Sexta/Sabado/Domingo\",\n",
        "    \"alta_temporada\": \"1 se Dezembro ou Julho\"\n",
        "}\n",
        "\n",
        "for feat, descricao in features_derivadas.items():\n",
        "    print(f\"  {feat:20s} -> {descricao}\")\n",
        "\n",
        "print(\"\\nFEATURES AGREGADAS (MediaAtrasoTransformer):\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "features_agregadas = {\n",
        "    \"media_atraso_empresa\": \"Media historica de atraso da companhia\",\n",
        "    \"media_atraso_origem\": \"Media historica de atraso do aeroporto origem\",\n",
        "    \"media_atraso_destino\": \"Media historica de atraso do aeroporto destino\"\n",
        "}\n",
        "\n",
        "for feat, descricao in features_agregadas.items():\n",
        "    print(f\"  {feat:25s} -> {descricao}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"TOTAL DE FEATURES PARA O MODELO: {len(colunas_usar) + len(features_derivadas) + len(features_agregadas)}\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "YnnUHBN_n2si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3935e5d3-ce4b-4eb7-ecef-d0e51fa1b368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FEATURES DERIVADAS DE 'partida_prevista':\n",
            "================================================================================\n",
            "  hora_dia             -> Hora de 0 a 23 (ex: 14 para voos as 14h)\n",
            "  dia_semana           -> 0=Segunda, 6=Domingo\n",
            "  mes_ano              -> 1=Janeiro, 12=Dezembro\n",
            "  periodo_dia          -> Manha/Tarde/Noite/Madrugada\n",
            "  fim_de_semana        -> 1 se Sexta/Sabado/Domingo\n",
            "  alta_temporada       -> 1 se Dezembro ou Julho\n",
            "\n",
            "FEATURES AGREGADAS (MediaAtrasoTransformer):\n",
            "================================================================================\n",
            "  media_atraso_empresa      -> Media historica de atraso da companhia\n",
            "  media_atraso_origem       -> Media historica de atraso do aeroporto origem\n",
            "  media_atraso_destino      -> Media historica de atraso do aeroporto destino\n",
            "\n",
            "================================================================================\n",
            "TOTAL DE FEATURES PARA O MODELO: 14\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# MODELO: CLASSIFICACAO BINARIA COM PROBABILIDADES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nTIPO DE MODELO:\")\n",
        "print(\"=\"*80)\n",
        "print(\"Classificacao Binaria:\")\n",
        "print(\"  - Classe 0: Voo Pontual (atraso <= 15 min)\")\n",
        "print(\"  - Classe 1: Voo Atrasado (atraso > 15 min)\")\n",
        "\n",
        "print(\"\\nOUTPUT DO MODELO:\")\n",
        "print(\"  1. Predicao: 0 ou 1 (classe prevista)\")\n",
        "print(\"  2. Probabilidade: 0.0 a 1.0 (confianca da predicao)\")\n",
        "\n",
        "print(\"\\nEXEMPLO:\")\n",
        "print(\"  Input:  Voo TAM, SBGR -> SBSP, Segunda 14h\")\n",
        "print(\"  Output: Classe = 1 (Atrasado)\")\n",
        "print(\"          Probabilidade = 0.73 (73% de chance de atraso)\")\n",
        "\n",
        "print(\"\\nMODELOS QUE RETORNAM PROBABILIDADE:\")\n",
        "print(\"  - LogisticRegression     -> model.predict_proba(X)\")\n",
        "print(\"  - RandomForestClassifier -> model.predict_proba(X)\")\n",
        "print(\"  - XGBoost                -> model.predict_proba(X)\")\n",
        "print(\"  - LightGBM               -> model.predict_proba(X)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DS3 vai treinar modelo que retorna CLASSE e PROBABILIDADE\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql-PyC-MpqV9",
        "outputId": "83d60321-da66-4e04-877f-28a25c38b6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TIPO DE MODELO:\n",
            "================================================================================\n",
            "Classificacao Binaria:\n",
            "  - Classe 0: Voo Pontual (atraso <= 15 min)\n",
            "  - Classe 1: Voo Atrasado (atraso > 15 min)\n",
            "\n",
            "OUTPUT DO MODELO:\n",
            "  1. Predicao: 0 ou 1 (classe prevista)\n",
            "  2. Probabilidade: 0.0 a 1.0 (confianca da predicao)\n",
            "\n",
            "EXEMPLO:\n",
            "  Input:  Voo TAM, SBGR -> SBSP, Segunda 14h\n",
            "  Output: Classe = 1 (Atrasado)\n",
            "          Probabilidade = 0.73 (73% de chance de atraso)\n",
            "\n",
            "MODELOS QUE RETORNAM PROBABILIDADE:\n",
            "  - LogisticRegression     -> model.predict_proba(X)\n",
            "  - RandomForestClassifier -> model.predict_proba(X)\n",
            "  - XGBoost                -> model.predict_proba(X)\n",
            "  - LightGBM               -> model.predict_proba(X)\n",
            "\n",
            "================================================================================\n",
            "DS3 vai treinar modelo que retorna CLASSE e PROBABILIDADE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# RESUMO: O QUE O MODELO VAI USAR\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMO FINAL: FEATURES PARA O MODELO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nUSAREMOS (informacoes disponiveis ANTES do voo):\")\n",
        "print(\"  1. empresa_aerea          - Qual companhia\")\n",
        "print(\"  2. aerodromo_origem       - De onde sai\")\n",
        "print(\"  3. aerodromo_destino      - Para onde vai\")\n",
        "print(\"  4. codigo_tipo_linha      - Tipo de voo\")\n",
        "print(\"  5. hora_dia               - Que hora do dia\")\n",
        "print(\"  6. dia_semana             - Que dia da semana\")\n",
        "print(\"  7. mes_ano                - Que mes\")\n",
        "print(\"  8. periodo_dia            - Manha/Tarde/Noite/Madrugada\")\n",
        "print(\"  9. fim_de_semana          - Se e fim de semana\")\n",
        "print(\" 10. alta_temporada         - Se e alta temporada\")\n",
        "print(\" 11. media_atraso_empresa   - Historico da companhia\")\n",
        "print(\" 12. media_atraso_origem    - Historico do aeroporto origem\")\n",
        "print(\" 13. media_atraso_destino   - Historico do aeroporto destino\")\n",
        "\n",
        "print(\"\\nNAO USAREMOS (informacoes so disponiveis DEPOIS do voo):\")\n",
        "print(\"  - partida_real\")\n",
        "print(\"  - chegada_real\")\n",
        "print(\"  - atraso_partida_min\")\n",
        "print(\"  - situacao_partida\")\n",
        "print(\"  - situacao_voo\")\n",
        "\n",
        "print(\"\\nTARGET (o que queremos prever):\")\n",
        "print(\"  - atrasado (0=Pontual, 1=Atrasado)\")\n",
        "\n",
        "print(\"\\nOUTPUT DO MODELO NA API:\")\n",
        "print(\"  - Classe: 0 ou 1\")\n",
        "print(\"  - Probabilidade: 0.0 a 1.0\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ],
      "metadata": {
        "id": "hs2vgyXcpuaR",
        "outputId": "f15e0791-8f02-45e4-f043-bed401edae87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RESUMO FINAL: FEATURES PARA O MODELO\n",
            "================================================================================\n",
            "\n",
            "USAREMOS (informacoes disponiveis ANTES do voo):\n",
            "  1. empresa_aerea          - Qual companhia\n",
            "  2. aerodromo_origem       - De onde sai\n",
            "  3. aerodromo_destino      - Para onde vai\n",
            "  4. codigo_tipo_linha      - Tipo de voo\n",
            "  5. hora_dia               - Que hora do dia\n",
            "  6. dia_semana             - Que dia da semana\n",
            "  7. mes_ano                - Que mes\n",
            "  8. periodo_dia            - Manha/Tarde/Noite/Madrugada\n",
            "  9. fim_de_semana          - Se e fim de semana\n",
            " 10. alta_temporada         - Se e alta temporada\n",
            " 11. media_atraso_empresa   - Historico da companhia\n",
            " 12. media_atraso_origem    - Historico do aeroporto origem\n",
            " 13. media_atraso_destino   - Historico do aeroporto destino\n",
            "\n",
            "NAO USAREMOS (informacoes so disponiveis DEPOIS do voo):\n",
            "  - partida_real\n",
            "  - chegada_real\n",
            "  - atraso_partida_min\n",
            "  - situacao_partida\n",
            "  - situacao_voo\n",
            "\n",
            "TARGET (o que queremos prever):\n",
            "  - atrasado (0=Pontual, 1=Atrasado)\n",
            "\n",
            "OUTPUT DO MODELO NA API:\n",
            "  - Classe: 0 ou 1\n",
            "  - Probabilidade: 0.0 a 1.0\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Celulas de 4 á 16"
      ],
      "metadata": {
        "id": "kZNDOtutsytf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Celula 4\n"
      ],
      "metadata": {
        "id": "iqAWyH0os9oX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CRIAR AMOSTRA ESTRATIFICADA (10%)\n",
        "# ============================================\n",
        "\n",
        "print(\"Criando amostra estratificada...\")\n",
        "print(\"Motivo: Evitar explosao de memoria no OneHotEncoder\")\n",
        "\n",
        "df_sample, _ = train_test_split(\n",
        "    df,\n",
        "    test_size=0.90,\n",
        "    random_state=42,\n",
        "    stratify=df['atrasado']\n",
        ")\n",
        "\n",
        "print(f\"\\nAmostragem concluida:\")\n",
        "print(f\"   Dataset original: {df.shape[0]:,} linhas\")\n",
        "print(f\"   Amostra (10%):    {df_sample.shape[0]:,} linhas\")\n",
        "print(f\"\\n   Distribuicao preservada:\")\n",
        "print(f\"   - Pontuais:  {(1-df_sample['atrasado'].mean())*100:.1f}%\")\n",
        "print(f\"   - Atrasados: {df_sample['atrasado'].mean()*100:.1f}%\")\n",
        "\n",
        "del df\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\nMemoria liberada\")\n"
      ],
      "metadata": {
        "id": "PNniVGSArCf2",
        "outputId": "da027d25-2285-4696-cf7e-5bb9fe1bd04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando amostra estratificada...\n",
            "Motivo: Evitar explosao de memoria no OneHotEncoder\n",
            "\n",
            "Amostragem concluida:\n",
            "   Dataset original: 3,642,571 linhas\n",
            "   Amostra (10%):    364,257 linhas\n",
            "\n",
            "   Distribuicao preservada:\n",
            "   - Pontuais:  84.0%\n",
            "   - Atrasados: 16.0%\n",
            "\n",
            "Memoria liberada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ============================================\n",
        "# DS2: FEATURES TEMPORAIS (FUNCAO REUTILIZAVEL)\n",
        "# ============================================\n",
        "\n",
        "def criar_features_temporais(df):\n",
        "    \"\"\"\n",
        "    Cria features derivadas de tempo a partir de 'partida_prevista'.\n",
        "\n",
        "    Features criadas:\n",
        "    - hora_dia: Hora de 0 a 23\n",
        "    - dia_semana: 0=Segunda, 6=Domingo\n",
        "    - mes_ano: 1=Janeiro, 12=Dezembro\n",
        "    - periodo_dia: Manha/Tarde/Noite/Madrugada\n",
        "    - fim_de_semana: 1 se Sexta/Sabado/Domingo\n",
        "    - alta_temporada: 1 se Dezembro ou Julho\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    df['hora_dia'] = df['partida_prevista'].dt.hour\n",
        "    df['dia_semana'] = df['partida_prevista'].dt.dayofweek\n",
        "    df['mes_ano'] = df['partida_prevista'].dt.month\n",
        "\n",
        "    def classificar_periodo(hora):\n",
        "        if 5 <= hora < 12:\n",
        "            return 'Manha'\n",
        "        elif 12 <= hora < 18:\n",
        "            return 'Tarde'\n",
        "        elif 18 <= hora < 22:\n",
        "            return 'Noite'\n",
        "        else:\n",
        "            return 'Madrugada'\n",
        "\n",
        "    df['periodo_dia'] = df['hora_dia'].apply(classificar_periodo)\n",
        "    df['fim_de_semana'] = df['dia_semana'].isin([4, 5, 6]).astype(int)\n",
        "    df['alta_temporada'] = df['mes_ano'].isin([7, 12]).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"Funcao criar_features_temporais() criada\")\n",
        "print(\"\\nFeatures que serao criadas:\")\n",
        "print(\"  1. hora_dia (0-23)\")\n",
        "print(\"  2. dia_semana (0-6)\")\n",
        "print(\"  3. mes_ano (1-12)\")\n",
        "print(\"  4. periodo_dia (Manha/Tarde/Noite/Madrugada)\")\n",
        "print(\"  5. fim_de_semana (0/1)\")\n",
        "print(\"  6. alta_temporada (0/1)\")\n"
      ],
      "metadata": {
        "id": "ujhAAx9isgLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88dd7373-39a9-4768-e55c-6bad2d01bcb0",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Funcao criar_features_temporais() criada\n",
            "\n",
            "Features que serao criadas:\n",
            "  1. hora_dia (0-23)\n",
            "  2. dia_semana (0-6)\n",
            "  3. mes_ano (1-12)\n",
            "  4. periodo_dia (Manha/Tarde/Noite/Madrugada)\n",
            "  5. fim_de_semana (0/1)\n",
            "  6. alta_temporada (0/1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DS2: CUSTOM TRANSFORMER PARA MEDIAS\n",
        "# ============================================\n",
        "\n",
        "class MediaAtrasoTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer customizado para criar features de media de atraso.\n",
        "\n",
        "    PROBLEMA RESOLVIDO:\n",
        "    Na Semana 1, criamos features com groupby() direto no DataFrame.\n",
        "    Isso NAO funciona na API porque a API recebe 1 voo por vez.\n",
        "\n",
        "    SOLUCAO:\n",
        "    - No fit(): Aprende as medias usando dados de treino\n",
        "    - No transform(): Aplica medias aprendidas (funciona com 1 linha)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.medias_empresa = {}\n",
        "        self.medias_origem = {}\n",
        "        self.medias_destino = {}\n",
        "        self.media_global = 0\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"  [MediaAtrasoTransformer] Aprendendo medias...\")\n",
        "\n",
        "        self.medias_empresa = (\n",
        "            X.groupby('empresa_aerea')['atraso_partida_min']\n",
        "            .mean()\n",
        "            .to_dict()\n",
        "        )\n",
        "\n",
        "        self.medias_origem = (\n",
        "            X.groupby('aerodromo_origem')['atraso_partida_min']\n",
        "            .mean()\n",
        "            .to_dict()\n",
        "        )\n",
        "\n",
        "        self.medias_destino = (\n",
        "            X.groupby('aerodromo_destino')['atraso_partida_min']\n",
        "            .mean()\n",
        "            .to_dict()\n",
        "        )\n",
        "\n",
        "        self.media_global = X['atraso_partida_min'].mean()\n",
        "\n",
        "        print(f\"  Medias aprendidas:\")\n",
        "        print(f\"     - {len(self.medias_empresa)} empresas\")\n",
        "        print(f\"     - {len(self.medias_origem)} aeroportos origem\")\n",
        "        print(f\"     - {len(self.medias_destino)} aeroportos destino\")\n",
        "        print(f\"     - Media global (fallback): {self.media_global:.2f} min\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        X['media_atraso_empresa'] = (\n",
        "            X['empresa_aerea']\n",
        "            .map(self.medias_empresa)\n",
        "            .fillna(self.media_global)\n",
        "        )\n",
        "\n",
        "        X['media_atraso_origem'] = (\n",
        "            X['aerodromo_origem']\n",
        "            .map(self.medias_origem)\n",
        "            .fillna(self.media_global)\n",
        "        )\n",
        "\n",
        "        X['media_atraso_destino'] = (\n",
        "            X['aerodromo_destino']\n",
        "            .map(self.medias_destino)\n",
        "            .fillna(self.media_global)\n",
        "        )\n",
        "\n",
        "        return X\n",
        "\n",
        "print(\"MediaAtrasoTransformer criado\")\n",
        "print(\"\\nPor que isso e importante?\")\n",
        "print(\"  - API recebe 1 voo por vez (nao tem acesso a outros voos)\")\n",
        "print(\"  - Transformer 'lembra' medias do treino e aplica em dados novos\")\n",
        "print(\"  - Funciona tanto em treino quanto em producao\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIQ8gs67tZCy",
        "outputId": "6999ec12-47a4-42f3-9dc3-9c91c49e747e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MediaAtrasoTransformer criado\n",
            "\n",
            "Por que isso e importante?\n",
            "  - API recebe 1 voo por vez (nao tem acesso a outros voos)\n",
            "  - Transformer 'lembra' medias do treino e aplica em dados novos\n",
            "  - Funciona tanto em treino quanto em producao\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# APLICAR FEATURES TEMPORAIS NO DATASET\n",
        "# ============================================\n",
        "\n",
        "print(\"Aplicando features temporais...\")\n",
        "\n",
        "df_sample = criar_features_temporais(df_sample)\n",
        "\n",
        "print(\"Features temporais criadas\")\n",
        "print(\"\\nExemplo das novas features:\")\n",
        "print(df_sample[['partida_prevista', 'hora_dia', 'periodo_dia',\n",
        "                  'fim_de_semana', 'alta_temporada']].head(10))\n",
        "\n",
        "print(f\"\\nShape atual: {df_sample.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCyBPe7GtRoR",
        "outputId": "1e806d81-8801-4b8f-a793-836bffa1e15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando features temporais...\n",
            "Features temporais criadas\n",
            "\n",
            "Exemplo das novas features:\n",
            "           partida_prevista  hora_dia periodo_dia  fim_de_semana  \\\n",
            "1619724 2023-10-29 17:20:00        17       Tarde              1   \n",
            "3497825 2025-01-19 08:30:00         8       Manha              1   \n",
            "2890320 2024-02-16 12:50:00        12       Tarde              1   \n",
            "3457695 2024-09-18 14:15:00        14       Tarde              0   \n",
            "2593466 2024-10-05 10:35:00        10       Manha              1   \n",
            "1731633 2023-11-14 19:10:00        19       Noite              0   \n",
            "2254243 2023-07-24 08:50:00         8       Manha              0   \n",
            "2290712 2023-07-29 15:40:00        15       Tarde              1   \n",
            "1235956 2022-06-06 11:25:00        11       Manha              0   \n",
            "1382793 2022-08-18 07:40:00         7       Manha              0   \n",
            "\n",
            "         alta_temporada  \n",
            "1619724               0  \n",
            "3497825               0  \n",
            "2890320               0  \n",
            "3457695               0  \n",
            "2593466               0  \n",
            "1731633               0  \n",
            "2254243               1  \n",
            "2290712               1  \n",
            "1235956               0  \n",
            "1382793               0  \n",
            "\n",
            "Shape atual: (364257, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DS1: DEFINIR FEATURES PARA O PIPELINE\n",
        "# ============================================\n",
        "\n",
        "print(\"Definindo features para o pipeline...\")\n",
        "\n",
        "target = 'atrasado'\n",
        "\n",
        "# Features originais que usaremos\n",
        "features_originais = [\n",
        "    'empresa_aerea',\n",
        "    'aerodromo_origem',\n",
        "    'aerodromo_destino',\n",
        "    'codigo_tipo_linha'\n",
        "]\n",
        "\n",
        "# Features numericas base (criadas por criar_features_temporais)\n",
        "numeric_features_base = [\n",
        "    'hora_dia',\n",
        "    'dia_semana',\n",
        "    'mes_ano',\n",
        "    'fim_de_semana',\n",
        "    'alta_temporada'\n",
        "]\n",
        "\n",
        "# Features categoricas\n",
        "categorical_features = [\n",
        "    'empresa_aerea',\n",
        "    'aerodromo_origem',\n",
        "    'aerodromo_destino',\n",
        "    'codigo_tipo_linha',\n",
        "    'periodo_dia'\n",
        "]\n",
        "\n",
        "# Colunas necessarias para MediaAtrasoTransformer\n",
        "# IMPORTANTE: atraso_partida_min so e usado para APRENDER as medias no treino\n",
        "# Na API, nao precisaremos dessa coluna (usaremos as medias pre-calculadas)\n",
        "colunas_para_medias = [\n",
        "    'empresa_aerea',\n",
        "    'aerodromo_origem',\n",
        "    'aerodromo_destino',\n",
        "    'atraso_partida_min'\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURES DEFINIDAS PARA O MODELO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n1. FEATURES ORIGINAIS ({len(features_originais)}):\")\n",
        "for f in features_originais:\n",
        "    print(f\"   - {f}\")\n",
        "\n",
        "print(f\"\\n2. FEATURES NUMERICAS DERIVADAS ({len(numeric_features_base)}):\")\n",
        "for f in numeric_features_base:\n",
        "    print(f\"   - {f}\")\n",
        "\n",
        "print(f\"\\n3. FEATURES CATEGORICAS ({len(categorical_features)}):\")\n",
        "for f in categorical_features:\n",
        "    print(f\"   - {f}\")\n",
        "\n",
        "print(f\"\\n4. FEATURES AGREGADAS (criadas pelo MediaAtrasoTransformer):\")\n",
        "print(\"   - media_atraso_empresa\")\n",
        "print(\"   - media_atraso_origem\")\n",
        "print(\"   - media_atraso_destino\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"TOTAL: {len(numeric_features_base) + 3 + len(categorical_features)} features\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nNOTA IMPORTANTE:\")\n",
        "print(\"  'atraso_partida_min' e usado APENAS para treinar o MediaAtrasoTransformer\")\n",
        "print(\"  Na API, nao precisaremos dessa coluna (usaremos medias pre-calculadas)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiHuKAMxpiSH",
        "outputId": "6c1d5db5-a8ae-4f91-9c66-0ee39223662d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Definindo features para o pipeline...\n",
            "\n",
            "================================================================================\n",
            "FEATURES DEFINIDAS PARA O MODELO\n",
            "================================================================================\n",
            "\n",
            "1. FEATURES ORIGINAIS (4):\n",
            "   - empresa_aerea\n",
            "   - aerodromo_origem\n",
            "   - aerodromo_destino\n",
            "   - codigo_tipo_linha\n",
            "\n",
            "2. FEATURES NUMERICAS DERIVADAS (5):\n",
            "   - hora_dia\n",
            "   - dia_semana\n",
            "   - mes_ano\n",
            "   - fim_de_semana\n",
            "   - alta_temporada\n",
            "\n",
            "3. FEATURES CATEGORICAS (5):\n",
            "   - empresa_aerea\n",
            "   - aerodromo_origem\n",
            "   - aerodromo_destino\n",
            "   - codigo_tipo_linha\n",
            "   - periodo_dia\n",
            "\n",
            "4. FEATURES AGREGADAS (criadas pelo MediaAtrasoTransformer):\n",
            "   - media_atraso_empresa\n",
            "   - media_atraso_origem\n",
            "   - media_atraso_destino\n",
            "\n",
            "================================================================================\n",
            "TOTAL: 13 features\n",
            "================================================================================\n",
            "\n",
            "NOTA IMPORTANTE:\n",
            "  'atraso_partida_min' e usado APENAS para treinar o MediaAtrasoTransformer\n",
            "  Na API, nao precisaremos dessa coluna (usaremos medias pre-calculadas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SEPARAR X (FEATURES) E y (TARGET)\n",
        "# ============================================\n",
        "\n",
        "print(\"Separando features (X) e target (y)...\")\n",
        "\n",
        "colunas_necessarias = numeric_features_base + categorical_features + colunas_para_medias\n",
        "colunas_necessarias = list(dict.fromkeys(colunas_necessarias))\n",
        "\n",
        "X = df_sample[colunas_necessarias].copy()\n",
        "y = df_sample[target].copy()\n",
        "\n",
        "print(f\"\\nSeparacao concluida:\")\n",
        "print(f\"   X shape: {X.shape}\")\n",
        "print(f\"   y shape: {y.shape}\")\n",
        "print(f\"\\n   Distribuicao do target:\")\n",
        "print(f\"   - Classe 0 (Pontual):  {(y==0).sum():,} ({(y==0).mean()*100:.1f}%)\")\n",
        "print(f\"   - Classe 1 (Atrasado): {(y==1).sum():,} ({(y==1).mean()*100:.1f}%)\")\n"
      ],
      "metadata": {
        "id": "ZTBEcadTrG-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a79dcb7-a0f3-4cd5-d73b-6217b1ae71ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Separando features (X) e target (y)...\n",
            "\n",
            "Separacao concluida:\n",
            "   X shape: (364257, 11)\n",
            "   y shape: (364257,)\n",
            "\n",
            "   Distribuicao do target:\n",
            "   - Classe 0 (Pontual):  306,073 (84.0%)\n",
            "   - Classe 1 (Atrasado): 58,184 (16.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DS2: APLICAR MEDIAARASOTRANSFORMER\n",
        "# ============================================\n",
        "\n",
        "print(\"Aplicando MediaAtrasoTransformer...\")\n",
        "print(\"(Criando features: media_atraso_empresa, media_atraso_origem, media_atraso_destino)\\n\")\n",
        "\n",
        "media_transformer = MediaAtrasoTransformer()\n",
        "X_com_medias = media_transformer.fit_transform(X)\n",
        "\n",
        "print(f\"\\nTransformer aplicado\")\n",
        "print(f\"   Shape antes:  {X.shape}\")\n",
        "print(f\"   Shape depois: {X_com_medias.shape}\")\n",
        "print(f\"\\nNovas colunas criadas:\")\n",
        "print(X_com_medias[['empresa_aerea', 'media_atraso_empresa',\n",
        "                     'aerodromo_origem', 'media_atraso_origem',\n",
        "                     'aerodromo_destino', 'media_atraso_destino']].head())\n"
      ],
      "metadata": {
        "id": "OAdrTMVCrGd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6820ddac-639c-4c31-89b4-d11ec83342ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando MediaAtrasoTransformer...\n",
            "(Criando features: media_atraso_empresa, media_atraso_origem, media_atraso_destino)\n",
            "\n",
            "  [MediaAtrasoTransformer] Aprendendo medias...\n",
            "  Medias aprendidas:\n",
            "     - 126 empresas\n",
            "     - 329 aeroportos origem\n",
            "     - 328 aeroportos destino\n",
            "     - Media global (fallback): 5.67 min\n",
            "\n",
            "Transformer aplicado\n",
            "   Shape antes:  (364257, 11)\n",
            "   Shape depois: (364257, 14)\n",
            "\n",
            "Novas colunas criadas:\n",
            "        empresa_aerea  media_atraso_empresa aerodromo_origem  \\\n",
            "1619724           AZU              3.164909             SBRF   \n",
            "3497825           AZU              3.164909             SBCF   \n",
            "2890320           TAM              3.746490             SBCT   \n",
            "3457695           TAM              3.746490             SBFZ   \n",
            "2593466           AZU              3.164909             SBPS   \n",
            "\n",
            "         media_atraso_origem aerodromo_destino  media_atraso_destino  \n",
            "1619724             3.416646              SBSV              5.376899  \n",
            "3497825             4.519614              SBCT              5.004950  \n",
            "2890320             3.178196              SBGR              6.978805  \n",
            "3457695             3.536754              SBEG             12.550698  \n",
            "2593466             3.569054              SBCF              4.063477  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DS1: PIPELINE DE PRE-PROCESSAMENTO\n",
        "# ============================================\n",
        "\n",
        "print(\"Criando pipeline de pre-processamento...\")\n",
        "\n",
        "numeric_features_final = numeric_features_base + [\n",
        "    'media_atraso_empresa',\n",
        "    'media_atraso_origem',\n",
        "    'media_atraso_destino'\n",
        "]\n",
        "\n",
        "print(f\"\\n1. Pipeline para NUMERICAS ({len(numeric_features_final)} features):\")\n",
        "print(\"   - Imputer: Preencher nulos com mediana\")\n",
        "print(\"   - Scaler: Normalizar (media=0, std=1)\")\n",
        "\n",
        "print(f\"\\n2. Pipeline para CATEGORICAS ({len(categorical_features)} features):\")\n",
        "print(\"   - Imputer: Preencher nulos com 'DESCONHECIDO'\")\n",
        "print(\"   - Encoder: OrdinalEncoder (evita explosao de dimensao)\")\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_features_final),\n",
        "\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='DESCONHECIDO')),\n",
        "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "    ]), categorical_features)\n",
        "], remainder='drop')\n",
        "\n",
        "print(\"\\nPipeline criado\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHpiV5eautwP",
        "outputId": "e8b4d195-c6aa-4126-976e-1e036c9218fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando pipeline de pre-processamento...\n",
            "\n",
            "1. Pipeline para NUMERICAS (8 features):\n",
            "   - Imputer: Preencher nulos com mediana\n",
            "   - Scaler: Normalizar (media=0, std=1)\n",
            "\n",
            "2. Pipeline para CATEGORICAS (5 features):\n",
            "   - Imputer: Preencher nulos com 'DESCONHECIDO'\n",
            "   - Encoder: OrdinalEncoder (evita explosao de dimensao)\n",
            "\n",
            "Pipeline criado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# APLICAR PIPELINE COMPLETO\n",
        "# ============================================\n",
        "\n",
        "print(\"Aplicando pipeline de pre-processamento...\\n\")\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X_com_medias)\n",
        "\n",
        "print(f\"Pipeline aplicado com sucesso\")\n",
        "print(f\"\\n   Shape original:   {X.shape}\")\n",
        "print(f\"   Shape processado: {X_processed.shape}\")\n",
        "print(f\"\\n   Tipo dos dados: {type(X_processed)}\")\n",
        "print(f\"   Memoria usada: {X_processed.nbytes / 1024**2:.1f} MB\")\n",
        "\n",
        "print(\"\\nDados prontos para treino do modelo\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1NONirMutlg",
        "outputId": "369862f8-bf79-4e73-e86b-c3eadcfdc07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando pipeline de pre-processamento...\n",
            "\n",
            "Pipeline aplicado com sucesso\n",
            "\n",
            "   Shape original:   (364257, 11)\n",
            "   Shape processado: (364257, 13)\n",
            "\n",
            "   Tipo dos dados: <class 'numpy.ndarray'>\n",
            "   Memoria usada: 36.1 MB\n",
            "\n",
            "Dados prontos para treino do modelo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SALVAR PIPELINES (ENTREGAVEIS)\n",
        "# ============================================\n",
        "\n",
        "print(\"Salvando pipelines...\")\n",
        "\n",
        "with open('media_transformer_ds2.pkl', 'wb') as f:\n",
        "    pickle.dump(media_transformer, f)\n",
        "print(\"Salvo: media_transformer_ds2.pkl\")\n",
        "\n",
        "with open('preprocessor_ds1.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)\n",
        "print(\"Salvo: preprocessor_ds1.pkl\")\n",
        "\n",
        "np.save('X_train_processed.npy', X_processed)\n",
        "np.save('y_train.npy', y.values)\n",
        "print(\"Salvo: X_train_processed.npy\")\n",
        "print(\"Salvo: y_train.npy\")\n",
        "\n",
        "print(\"\\nTodos os arquivos salvos\")\n",
        "print(\"\\nArquivos criados:\")\n",
        "print(\"  1. media_transformer_ds2.pkl\")\n",
        "print(\"  2. preprocessor_ds1.pkl\")\n",
        "print(\"  3. X_train_processed.npy\")\n",
        "print(\"  4. y_train.npy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxkWthtiuta0",
        "outputId": "cf08e0a9-2dfb-4725-fa54-d1f3b61bba68"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salvando pipelines...\n",
            "Salvo: media_transformer_ds2.pkl\n",
            "Salvo: preprocessor_ds1.pkl\n",
            "Salvo: X_train_processed.npy\n",
            "Salvo: y_train.npy\n",
            "\n",
            "Todos os arquivos salvos\n",
            "\n",
            "Arquivos criados:\n",
            "  1. media_transformer_ds2.pkl\n",
            "  2. preprocessor_ds1.pkl\n",
            "  3. X_train_processed.npy\n",
            "  4. y_train.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TESTE: SIMULAR RECEBIMENTO DE NOVO VOO (API)\n",
        "# ============================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TESTE: SIMULANDO RECEBIMENTO DE NOVO VOO VIA API\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "novo_voo_json = {\n",
        "    'empresa_aerea': 'TAM',\n",
        "    'aerodromo_origem': 'SBGR',\n",
        "    'aerodromo_destino': 'SBSP',\n",
        "    'partida_prevista': '2024-12-25 20:30:00',\n",
        "    'atraso_partida_min': 0,\n",
        "    'codigo_tipo_linha': 'N' # Adicionando a coluna faltante\n",
        "}\n",
        "\n",
        "print(\"\\n1. JSON recebido pela API:\")\n",
        "print(json.dumps(novo_voo_json, indent=2, ensure_ascii=False))\n",
        "\n",
        "novo_voo_df = pd.DataFrame([novo_voo_json])\n",
        "novo_voo_df['partida_prevista'] = pd.to_datetime(novo_voo_df['partida_prevista'])\n",
        "\n",
        "print(\"\\n2. Aplicando criar_features_temporais()...\")\n",
        "novo_voo_df = criar_features_temporais(novo_voo_df)\n",
        "print(f\"   Features temporais criadas\")\n",
        "\n",
        "print(\"\\n3. Aplicando MediaAtrasoTransformer...\")\n",
        "novo_voo_com_medias = media_transformer.transform(novo_voo_df)\n",
        "print(f\"   Features agregadas criadas:\")\n",
        "print(f\"      - media_atraso_empresa: {novo_voo_com_medias['media_atraso_empresa'].values[0]:.2f} min\")\n",
        "print(f\"      - media_atraso_origem:  {novo_voo_com_medias['media_atraso_origem'].values[0]:.2f} min\")\n",
        "print(f\"      - media_atraso_destino: {novo_voo_com_medias['media_atraso_destino'].values[0]:.2f} min\")\n",
        "\n",
        "print(\"\\n4. Aplicando Preprocessor (normalizacao + encoding)...\")\n",
        "novo_voo_processed = preprocessor.transform(novo_voo_com_medias)\n",
        "print(f\"   Shape final: {novo_voo_processed.shape}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTE BEM-SUCEDIDO\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nO pipeline funciona corretamente com:\")\n",
        "print(\"  - DataFrame completo (milhoes de linhas)\")\n",
        "print(\"  - 1 voo individual (JSON da API)\")\n",
        "print(\"\\nPronto para DS3 treinar modelo e DS5 integrar com API\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_PPOa9vutOX",
        "outputId": "6a5606e1-8727-4325-8aea-8f54d2a251be"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TESTE: SIMULANDO RECEBIMENTO DE NOVO VOO VIA API\n",
            "================================================================================\n",
            "\n",
            "1. JSON recebido pela API:\n",
            "{\n",
            "  \"empresa_aerea\": \"TAM\",\n",
            "  \"aerodromo_origem\": \"SBGR\",\n",
            "  \"aerodromo_destino\": \"SBSP\",\n",
            "  \"partida_prevista\": \"2024-12-25 20:30:00\",\n",
            "  \"atraso_partida_min\": 0,\n",
            "  \"codigo_tipo_linha\": \"N\"\n",
            "}\n",
            "\n",
            "2. Aplicando criar_features_temporais()...\n",
            "   Features temporais criadas\n",
            "\n",
            "3. Aplicando MediaAtrasoTransformer...\n",
            "   Features agregadas criadas:\n",
            "      - media_atraso_empresa: 3.75 min\n",
            "      - media_atraso_origem:  8.65 min\n",
            "      - media_atraso_destino: 2.93 min\n",
            "\n",
            "4. Aplicando Preprocessor (normalizacao + encoding)...\n",
            "   Shape final: (1, 13)\n",
            "\n",
            "================================================================================\n",
            "TESTE BEM-SUCEDIDO\n",
            "================================================================================\n",
            "\n",
            "O pipeline funciona corretamente com:\n",
            "  - DataFrame completo (milhoes de linhas)\n",
            "  - 1 voo individual (JSON da API)\n",
            "\n",
            "Pronto para DS3 treinar modelo e DS5 integrar com API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DOCUMENTACAO COMPLETA (DS1 + DS2)\n",
        "# ============================================\n",
        "\n",
        "documentacao = {\n",
        "    \"projeto\": \"Hackathon - Previsao de Atrasos de Voo\",\n",
        "    \"semana\": 2,\n",
        "    \"data\": \"23/12/2025\",\n",
        "    \"responsaveis\": {\n",
        "        \"DS1_Preprocessamento\": \"Ana\",\n",
        "        \"DS2_FeatureEngineering\": \"Amelia\"\n",
        "    },\n",
        "    \"DS1_Preprocessamento\": {\n",
        "        \"amostragem\": {\n",
        "            \"motivo\": \"Evitar explosao de memoria no OneHotEncoder\",\n",
        "            \"metodo\": \"Amostra estratificada de 10%\",\n",
        "            \"distribuicao_preservada\": True\n",
        "        },\n",
        "        \"tratamento_nulos\": {\n",
        "            \"numericas\": \"Mediana (SimpleImputer)\",\n",
        "            \"categoricas\": \"Constante 'DESCONHECIDO' (SimpleImputer)\"\n",
        "        },\n",
        "        \"normalizacao\": \"StandardScaler (media=0, std=1)\",\n",
        "        \"encoding\": \"OrdinalEncoder (evita explosao de dimensao)\",\n",
        "        \"features_numericas\": numeric_features_final,\n",
        "        \"features_categoricas\": categorical_features\n",
        "    },\n",
        "    \"DS2_FeatureEngineering\": {\n",
        "        \"features_temporais\": {\n",
        "            \"hora_dia\": \"0-23\",\n",
        "            \"dia_semana\": \"0=Segunda, 6=Domingo\",\n",
        "            \"mes_ano\": \"1-12\",\n",
        "            \"periodo_dia\": \"Manha/Tarde/Noite/Madrugada\",\n",
        "            \"fim_de_semana\": \"Sexta/Sabado/Domingo = 1\",\n",
        "            \"alta_temporada\": \"Dezembro/Julho = 1\"\n",
        "        },\n",
        "        \"features_agregadas\": {\n",
        "            \"media_atraso_empresa\": \"Media historica por companhia\",\n",
        "            \"media_atraso_origem\": \"Media historica por aeroporto origem\",\n",
        "            \"media_atraso_destino\": \"Media historica por aeroporto destino\"\n",
        "        }\n",
        "    },\n",
        "    \"entregaveis\": [\n",
        "        \"media_transformer_ds2.pkl\",\n",
        "        \"preprocessor_ds1.pkl\",\n",
        "        \"X_train_processed.npy\",\n",
        "        \"y_train.npy\",\n",
        "        \"documentacao_ds1_ds2.json\"\n",
        "    ],\n",
        "    \"proximo_passo\": \"DS3 treinar modelo baseline com X_train_processed.npy e y_train.npy\"\n",
        "}\n",
        "\n",
        "with open('documentacao_ds1_ds2.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(documentacao, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Documentacao salva: documentacao_ds1_ds2.json\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMO DA DOCUMENTACAO\")\n",
        "print(\"=\"*80)\n",
        "print(json.dumps(documentacao, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSskFL-HvAtk",
        "outputId": "0e5d07ae-9978-4ffc-b4f6-da772641d8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documentacao salva: documentacao_ds1_ds2.json\n",
            "\n",
            "================================================================================\n",
            "RESUMO DA DOCUMENTACAO\n",
            "================================================================================\n",
            "{\n",
            "  \"projeto\": \"Hackathon - Previsao de Atrasos de Voo\",\n",
            "  \"semana\": 2,\n",
            "  \"data\": \"23/12/2025\",\n",
            "  \"responsaveis\": {\n",
            "    \"DS1_Preprocessamento\": \"Ana\",\n",
            "    \"DS2_FeatureEngineering\": \"Amelia\"\n",
            "  },\n",
            "  \"DS1_Preprocessamento\": {\n",
            "    \"amostragem\": {\n",
            "      \"motivo\": \"Evitar explosao de memoria no OneHotEncoder\",\n",
            "      \"metodo\": \"Amostra estratificada de 10%\",\n",
            "      \"distribuicao_preservada\": true\n",
            "    },\n",
            "    \"tratamento_nulos\": {\n",
            "      \"numericas\": \"Mediana (SimpleImputer)\",\n",
            "      \"categoricas\": \"Constante 'DESCONHECIDO' (SimpleImputer)\"\n",
            "    },\n",
            "    \"normalizacao\": \"StandardScaler (media=0, std=1)\",\n",
            "    \"encoding\": \"OrdinalEncoder (evita explosao de dimensao)\",\n",
            "    \"features_numericas\": [\n",
            "      \"hora_dia\",\n",
            "      \"dia_semana\",\n",
            "      \"mes_ano\",\n",
            "      \"fim_de_semana\",\n",
            "      \"alta_temporada\",\n",
            "      \"media_atraso_empresa\",\n",
            "      \"media_atraso_origem\",\n",
            "      \"media_atraso_destino\"\n",
            "    ],\n",
            "    \"features_categoricas\": [\n",
            "      \"empresa_aerea\",\n",
            "      \"aerodromo_origem\",\n",
            "      \"aerodromo_destino\",\n",
            "      \"codigo_tipo_linha\",\n",
            "      \"periodo_dia\"\n",
            "    ]\n",
            "  },\n",
            "  \"DS2_FeatureEngineering\": {\n",
            "    \"features_temporais\": {\n",
            "      \"hora_dia\": \"0-23\",\n",
            "      \"dia_semana\": \"0=Segunda, 6=Domingo\",\n",
            "      \"mes_ano\": \"1-12\",\n",
            "      \"periodo_dia\": \"Manha/Tarde/Noite/Madrugada\",\n",
            "      \"fim_de_semana\": \"Sexta/Sabado/Domingo = 1\",\n",
            "      \"alta_temporada\": \"Dezembro/Julho = 1\"\n",
            "    },\n",
            "    \"features_agregadas\": {\n",
            "      \"media_atraso_empresa\": \"Media historica por companhia\",\n",
            "      \"media_atraso_origem\": \"Media historica por aeroporto origem\",\n",
            "      \"media_atraso_destino\": \"Media historica por aeroporto destino\"\n",
            "    }\n",
            "  },\n",
            "  \"entregaveis\": [\n",
            "    \"media_transformer_ds2.pkl\",\n",
            "    \"preprocessor_ds1.pkl\",\n",
            "    \"X_train_processed.npy\",\n",
            "    \"y_train.npy\",\n",
            "    \"documentacao_ds1_ds2.json\"\n",
            "  ],\n",
            "  \"proximo_passo\": \"DS3 treinar modelo baseline com X_train_processed.npy e y_train.npy\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# RESUMO FINAL - ENTREGA SEMANA 2\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMO FINAL - DS1 + DS2\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nOBJETIVOS CUMPRIDOS:\")\n",
        "print(\"\\nDS1 (Pre-processamento):\")\n",
        "print(\"  - Amostra estratificada (10%) criada\")\n",
        "print(\"  - Tratamento de nulos implementado\")\n",
        "print(\"  - Normalizacao (StandardScaler) aplicada\")\n",
        "print(\"  - Encoding (OrdinalEncoder) aplicado\")\n",
        "print(\"  - Pipeline reutilizavel criado\")\n",
        "\n",
        "print(\"\\nDS2 (Feature Engineering):\")\n",
        "print(\"  - Features temporais criadas (6 novas features)\")\n",
        "print(\"  - Features agregadas criadas (3 medias)\")\n",
        "print(\"  - MediaAtrasoTransformer implementado\")\n",
        "print(\"  - Solucao para problema do groupby() na API\")\n",
        "\n",
        "print(\"\\nARQUIVOS ENTREGUES:\")\n",
        "print(\"  1. media_transformer_ds2.pkl\")\n",
        "print(\"  2. preprocessor_ds1.pkl\")\n",
        "print(\"  3. X_train_processed.npy\")\n",
        "print(\"  4. y_train.npy\")\n",
        "print(\"  5. documentacao_ds1_ds2.json\")\n",
        "print(\"  6. S02_DS1_DS2_Pipeline.ipynb\")\n",
        "\n",
        "print(\"\\nPROXIMOS PASSOS:\")\n",
        "print(\"  - DS3: Carregar X_train_processed.npy e y_train.npy\")\n",
        "print(\"  - DS3: Treinar modelo baseline\")\n",
        "print(\"  - DS5: Integrar pipelines na API\")\n",
        "print(\"  - DS5: Testar endpoint /predict\")\n",
        "\n",
        "print(\"\\nAPRESENTACAO (Quinta 25/12):\")\n",
        "print(\"  1. Mostrar problema do groupby() na API\")\n",
        "print(\"  2. Explicar MediaAtrasoTransformer (solucao)\")\n",
        "print(\"  3. Demonstrar pipeline completo funcionando\")\n",
        "print(\"  4. Mostrar teste com novo voo (celula 14)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SEMANA 2 (DS1 + DS2) CONCLUIDA COM SUCESSO\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbIbD_acvAfc",
        "outputId": "0f7ea7a3-3731-4367-d041-76b46ceef15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RESUMO FINAL - DS1 + DS2\n",
            "================================================================================\n",
            "\n",
            "OBJETIVOS CUMPRIDOS:\n",
            "\n",
            "DS1 (Pre-processamento):\n",
            "  - Amostra estratificada (10%) criada\n",
            "  - Tratamento de nulos implementado\n",
            "  - Normalizacao (StandardScaler) aplicada\n",
            "  - Encoding (OrdinalEncoder) aplicado\n",
            "  - Pipeline reutilizavel criado\n",
            "\n",
            "DS2 (Feature Engineering):\n",
            "  - Features temporais criadas (6 novas features)\n",
            "  - Features agregadas criadas (3 medias)\n",
            "  - MediaAtrasoTransformer implementado\n",
            "  - Solucao para problema do groupby() na API\n",
            "\n",
            "ARQUIVOS ENTREGUES:\n",
            "  1. media_transformer_ds2.pkl\n",
            "  2. preprocessor_ds1.pkl\n",
            "  3. X_train_processed.npy\n",
            "  4. y_train.npy\n",
            "  5. documentacao_ds1_ds2.json\n",
            "  6. S02_DS1_DS2_Pipeline.ipynb\n",
            "\n",
            "PROXIMOS PASSOS:\n",
            "  - DS3: Carregar X_train_processed.npy e y_train.npy\n",
            "  - DS3: Treinar modelo baseline\n",
            "  - DS5: Integrar pipelines na API\n",
            "  - DS5: Testar endpoint /predict\n",
            "\n",
            "APRESENTACAO (Quinta 25/12):\n",
            "  1. Mostrar problema do groupby() na API\n",
            "  2. Explicar MediaAtrasoTransformer (solucao)\n",
            "  3. Demonstrar pipeline completo funcionando\n",
            "  4. Mostrar teste com novo voo (celula 14)\n",
            "\n",
            "================================================================================\n",
            "SEMANA 2 (DS1 + DS2) CONCLUIDA COM SUCESSO\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1Vqcc1RvAQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
