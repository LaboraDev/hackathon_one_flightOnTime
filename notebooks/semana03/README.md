# ğŸ“˜ Semana 03 â€” Aprimoramento e Robustez do Modelo

ApÃ³s a construÃ§Ã£o do pipeline inicial, do modelo baseline e da integraÃ§Ã£o com a API, a Semana 3 serÃ¡ dedicada a evoluir o modelo e o pipeline de forma organizada, consistente e reproduzÃ­vel. Nesta etapa, comeÃ§amos a tratar o pipeline como um componente central do projeto, responsÃ¡vel por garantir que todo o processo, do prÃ©-processamento Ã  prediÃ§Ã£o, funcione corretamente quando aplicado a dados novos.

O objetivo desta semana nÃ£o Ã© apenas melhorar mÃ©tricas, mas assegurar que qualquer avanÃ§o realizado, seja na escolha do modelo, na criaÃ§Ã£o de features ou na forma de avaliar o desempenho, esteja corretamente integrado ao pipeline. Isso Ã© essencial porque o modelo serÃ¡ utilizado em um cenÃ¡rio prÃ³ximo ao de produÃ§Ã£o, sendo acessado por meio da API e recebendo informaÃ§Ãµes que nÃ£o passaram por tratamentos manuais.

> **Regra fundamental:**  
> A partir desta semana, **toda transformaÃ§Ã£o utilizada pelo modelo deve estar dentro do pipeline**.  
> TransformaÃ§Ãµes feitas diretamente no dataframe devem ser usadas **apenas para anÃ¡lise**, nunca para treino ou prediÃ§Ã£o.

Todas as frentes devem partir do **Notebook Consolidado da Semana 2**, reutilizando o pipeline existente e implementando ajustes **exclusivamente por meio de funÃ§Ãµes, transformers ou novas etapas no pipeline**.

---

## ğŸ› ï¸ DS1 â€” Modelos Candidatos (EvoluÃ§Ã£o do Baseline)
**ResponsÃ¡vel:** Ana Raquel 

### Objetivo
O objetivo desta frente Ã© verificar se a escolha do algoritmo influencia significativamente o desempenho do modelo, partindo exatamente do mesmo conjunto de dados e do mesmo prÃ©-processamento definido na semana anterior. Em outras palavras, queremos entender se o resultado atual Ã© limitado pelo tipo de modelo utilizado ou se o gargalo estÃ¡ em outras partes do pipeline.

O foco nÃ£o Ã© criar novas features, alterar os dados ou ajustar parÃ¢metros finos dos modelos, mas sim comparar diferentes algoritmos de forma justa. Para isso, todos os modelos devem receber os dados da mesma forma, garantindo que qualquer diferenÃ§a de desempenho observada esteja relacionada apenas ao algoritmo escolhido.

O pipeline deve ser mantido inalterado, com exceÃ§Ã£o do estimador final. Ao final desta frente, esperamos identificar se modelos mais robustos conseguem trazer ganhos reais em relaÃ§Ã£o ao baseline atual ou se a melhoria do desempenho depende principalmente de outras estratÃ©gias, como aprimoramento de features ou validaÃ§Ã£o.

### Tarefas
- Substituir o modelo atual por pelo menos **trÃªs modelos de classificaÃ§Ã£o mais robustos**, como:
  - Ãrvores de decisÃ£o
  - KNN
  - SVM
  - Random Forest
- Treinar todos os modelos utilizando o **mesmo conjunto de features**
- Avaliar mÃ©tricas bÃ¡sicas:
  - AcurÃ¡cia
  - PrecisÃ£o
  - Sensibilidade (Recall)
  - F1-Score
- Comparar os resultados com o baseline atual

### Pergunta-chave
> **Qual modelo apresenta o melhor ganho real em relaÃ§Ã£o ao baseline atual?**

### ğŸ”– EntregÃ¡veis
- Notebook(s) com os testes dos modelos (pode ser um notebook por modelo)
- Pipeline completo com os modelos integrados
- Script `.py` com a definiÃ§Ã£o do pipeline e funÃ§Ãµes auxiliares (complemente o arquivo da Semana 2, se for o caso)
- ComparaÃ§Ã£o objetiva das mÃ©tricas entre os modelos testados

---

## ğŸ§© DS2 â€“ ValidaÃ§Ã£o e MÃ©tricas do Modelo 
**ResponsÃ¡vel:** Enoque  

### Objetivo
O objetivo desta frente Ã© verificar se o desempenho que estamos observando no modelo representa, de fato, o comportamento que ele terÃ¡ quando estiver em uso real. Como estamos trabalhando com dados de voos ao longo do tempo (2021-2024), Ã© importante lembrar que o modelo serÃ¡ treinado com dados do passado e utilizado para prever situaÃ§Ãµes atuais. 

O foco nÃ£o Ã© melhorar o modelo ou criar novas features, mas entender se a forma como estamos separando os dados para treino e teste influencia diretamente os resultados obtidos. Em outras palavras, queremos responder se o modelo estÃ¡ aprendendo padrÃµes reais ou se estÃ¡ apenas se beneficiando da forma como os dados foram divididos. 

Para isso, esta frente irÃ¡ comparar diferentes estratÃ©gias de divisÃ£o dos dados, como a divisÃ£o estratificada (que mantÃ©m a proporÃ§Ã£o das classes entre treino e teste) e a divisÃ£o temporal (que separa os dados respeitando a ordem do tempo, treinando com dados mais antigos e testando com dados mais recentes). A partir dessa comparaÃ§Ã£o, o objetivo Ã© avaliar como o desempenho do modelo se comporta em cada cenÃ¡rio e definir qual estratÃ©gia de avaliaÃ§Ã£o faz mais sentido para representar o uso real do modelo nas prÃ³ximas etapas do projeto

### Tarefas
- Implementar os dois tipos de split
  - Split estratificado 
  - Split temporal:
- Calcular mÃ©tricas para ambos os cenÃ¡rios
- Comparar diferenÃ§as de desempenho
- Definir qual divisÃ£o deve ser priorizada no projeto

### Pergunta-chave
> **O modelo mantÃ©m desempenho consistente em dados mais recentes ou o resultado depende do tipo de split utilizado?**

### ğŸ”– EntregÃ¡veis
- Notebook com comparaÃ§Ã£o clara entre os tipos de validaÃ§Ã£o (pode ser um notebook para cada split)
- Script `.py` com funÃ§Ãµes de avaliaÃ§Ã£o
- RecomendaÃ§Ã£o da melhor estratÃ©gia de validaÃ§Ã£o e mÃ©trica

---

## âš–ï¸ DS3 â€“ Aprimoramento de Features (GeraÃ§Ã£o de Sinal) 
**ResponsÃ¡vel:** AmÃ©lia  

### Objetivo
O objetivo desta frente Ã© aumentar a capacidade do modelo de identificar padrÃµes relevantes por meio da criaÃ§Ã£o de novas features, utilizando os aprendizados obtidos na anÃ¡lise exploratÃ³ria dos dados. Nesta etapa, buscamos explorar diferentes formas de representar as informaÃ§Ãµes disponÃ­veis, ajudando o modelo a capturar relaÃ§Ãµes que nÃ£o sÃ£o evidentes nas variÃ¡veis originais.

As novas features podem ser simples ou mais elaboradas, desde que faÃ§am sentido do ponto de vista do problema e agreguem informaÃ§Ã£o Ãºtil ao modelo. O ponto central desta frente Ã© avaliar se as transformaÃ§Ãµes propostas adicionam sinal real ao processo de prediÃ§Ã£o, contribuindo para uma melhor separaÃ§Ã£o entre os casos.

Ã‰ fundamental que todas as features criadas sejam implementadas de forma consistente e reprodutÃ­vel, integrando o pipeline, para garantir que o mesmo conjunto de transformaÃ§Ãµes seja aplicado tanto durante o treino quanto na prediÃ§Ã£o. Ao final desta etapa, esperamos identificar quais features realmente contribuem para melhorar o desempenho do modelo e quais podem ser descartadas

### Tarefas
-	Criar novas features dentro do pipeline, como por exemplo:
    - o	encoding cÃ­clico para variÃ¡veis temporais
    - o	agrupamento de categorias pouco frequentes;
    - o	contagens de voos por companhia ou aeroporto;
    - o	agrupar os aeroportos por regiÃµes;
-	Garantir que nenhuma feature seja criada manualmente no dataframe
-	Comparar mÃ©tricas antes vs depois da inclusÃ£o das novas features

### Pergunta-chave
> **Quais novas features melhoram o desempenho do modelo sem comprometer a reprodutibilidade do pipeline?**

### ğŸ”– EntregÃ¡veis
- Notebook atualizado com as novas features testadas
- Pipeline completo com as features integradas
- Script `.py` com funÃ§Ãµes ou transformers criados
- ComparaÃ§Ã£o objetiva de mÃ©tricas

---

## ğŸ§ª DS4 â€“ ConsolidaÃ§Ã£o TÃ©cnica e Estabilidade da API 
**ResponsÃ¡vel:** Helena  

### Objetivo
O objetivo desta frente Ã© reunir e integrar as melhorias desenvolvidas pelas demais frentes, garantindo que o pipeline final funcione de forma estÃ¡vel e consistente quando utilizado pela API. Nesta etapa, o foco Ã© verificar se todas as alteraÃ§Ãµes realizadas ao longo da semana estÃ£o corretamente incorporadas ao fluxo completo, desde o prÃ©-processamento atÃ© a prediÃ§Ã£o.

AlÃ©m de consolidar o pipeline, esta frente Ã© responsÃ¡vel por assegurar que o modelo esteja devidamente serializado e que a API continue operando conforme o esperado, mesmo apÃ³s as atualizaÃ§Ãµes. O objetivo Ã© manter o projeto organizado, reproduzÃ­vel e tecnicamente coerente, preparando a base para as prÃ³ximas etapas, como ajustes finos, anÃ¡lise de resultados e apresentaÃ§Ã£o final.

### Tarefas
- Integrar o modelo escolhido (DS1) e as features aprovadas (DS3)
-	Atualizar e serializar o pipeline final (.pkl)
-	Testar a API com o pipeline atualizado
-	Garantir compatibilidade com o contrato JSON
-	Atualizar o README com:
  - o	modelo atual
  - o	features utilizadas
  - o	mÃ©trica principal
  - o	limitaÃ§Ãµes conhecidas

### Pergunta-chave
> **O pipeline atualizado estÃ¡ estÃ¡vel, reproduzÃ­vel e pronto para avanÃ§ar sem retrabalho?**

### ğŸ”– EntregÃ¡veis
- Pipeline final serializado
- API funcionando com o pipeline atualizado
- README atualizado e padronizado

---

## ğŸ“… Cronograma da Semana 3 â€” Datas Importantes

### ğŸ—“ï¸ Segunda-feira â€” 29/12
**ReuniÃ£o de planejamento**
- Alinhamento das responsabilidades
- DÃºvidas tÃ©cnicas
- Checklist de arquivos
- Ajustes no cronograma

### ğŸ—“ï¸ Quinta-feira â€” 01/01
**DemonstraÃ§Ã£o das entregas**
- DS1: apresenta a comparaÃ§Ã£o de modelos
- DS2: mostra validaÃ§Ã£o dos dados (estratificado vs temporal)
- DS3: fala sobre os impactos das novas features

### ğŸ—“ï¸ Sexta-feira â€” 26/12
**ConsolidaÃ§Ã£o final**
- Escolha de:
  - 1 modelo
  - 1 estratÃ©gia de validaÃ§Ã£o
  - 1 conjunto final de features
- Congelamento do pipeline v2
- DocumentaÃ§Ã£o das decisÃµes

---

## â„¹ï¸ ObservaÃ§Ã£o Final
Planejei apenas as reuniÃµes obrigatÃ³rias da semana, mas poderemos marcar encontros adicionais conforme necessidade da equipe, especialmente para revisar passos tÃ©cnicos mais complexos. Estou a disposiÃ§Ã£o de vocÃªs.
