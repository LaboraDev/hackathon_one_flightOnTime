# -*- coding: utf-8 -*-
"""mod_sem_vaza_DS01_S3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jq8VJz2pPibS3n56tTkGDXU26Sy7bQqc
"""

# ==============================================================================
# CABE√áALHO: CONFIGURA√á√ÉO DE AMBIENTE E DEPEND√äNCIAS
# Objetivo: Instalar algoritmos de ponta e vincular o script_v3.py ao Colab.
# ==============================================================================
!pip install xgboost lightgbm imbalanced-learn gdown -q
import os
import script_v3 as sc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV

# ==============================================================================
# CABE√áALHO: INGEST√ÉO, EXTRA√á√ÉO E TARGET (DS1 - SEMANA 3)
# Objetivo: Baixar a base VRA do Drive, extrair e preparar o target para o modelo.
# ==============================================================================
import os
import zipfile
import glob
import gdown

# 1. Download e Extra√ß√£o Din√¢mica
file_id = "1207psedBKvnS0pJkDITroSzPiWrcz0ag"
zip_path = "dados_vra.zip"
extract_folder = "dados_vra"

if not os.path.exists(zip_path):
    print("‚è≥ Baixando arquivos da base VRA...")
    gdown.download(f"https://drive.google.com/uc?id={file_id}", zip_path, quiet=False)

if not os.path.exists(extract_folder):
    print("üì¶ Extraindo arquivos...")
    with zipfile.ZipFile(zip_path, 'r') as z:
        z.extractall(extract_folder)

# 2. Localiza√ß√£o Autom√°tica da Pasta de CSVs
def find_data_path():
    matches = glob.glob(os.path.join(os.getcwd(), "**/VRA_*.csv"), recursive=True)
    return os.path.dirname(matches[0]) if matches else None

data_path = find_data_path()
print(f"üìÇ Pasta de dados localizada: {data_path}")

# 3. Carregamento e Cria√ß√£o do Target (Usando script_v3)
df_atual = sc.carregar_dataset_base(pasta=data_path)
df_modelo = sc.criar_target_atrasado(sc.criar_flags_qualidade_basicas(df_atual))

# 4. Split Estratificado (DS2) - Amostra para agilidade no Hackathon
df_amostra = df_modelo.sample(n=30000, random_state=42)
df_train, df_test = sc.criar_split_estratificado(df_amostra, sc.TARGET_COL)

print(f"‚úÖ Sucesso! Dados prontos: {df_train.shape[0]} treino / {df_test.shape[0]} teste.")

# ==============================================================================
# CABE√áALHO: CONFIGURA√á√ÉO DE FEATURES (CONTROLE DE VAZAMENTO)
# Objetivo: Definir quais informa√ß√µes o modelo pode usar (Apenas o que se sabe antes do voo).
# ==============================================================================
# IMPORTANTE: Removidas colunas de 'atraso' real para evitar m√©tricas falsas de 1.0
cfg = sc.FeatureConfig(
    numeric_features=['hora_dia', 'dia_semana', 'mes_ano'],
    categorical_features=['empresa_aerea', 'aerodromo_origem', 'aerodromo_destino']
)

# ==============================================================================
# CABE√áALHO: COMPETI√á√ÉO DE MODELOS E MATRIZES DE CONFUS√ÉO
# Objetivo: Treinar modelos robustos e validar o erro atrav√©s de mapas de calor.
# ==============================================================================
modelos = {
    "Random Forest": RandomForestClassifier(max_depth=10, class_weight='balanced', random_state=42),
    "XGBoost": XGBClassifier(scale_pos_weight=4, random_state=42),
    "LightGBM": LGBMClassifier(class_weight='balanced', verbose=-1)
}

resultados = []
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for i, (nome, mod) in enumerate(modelos.items()):
    res = sc.treinar_classificador(df_train, df_test, cfg, mod)
    m = res['metrics']
    cm = np.array(m['confusion_matrix'])

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)
    axes[i].set_title(f"Matriz: {nome}")

    f1 = m.get('1', {}).get('f1-score', 0) or m.get(1, {}).get('f1-score', 0)
    resultados.append({'Modelo': nome, 'F1-Score': f1, 'ROC-AUC': m.get('roc_auc', 0)})

plt.show()

# ==============================================================================
# CABE√áALHO: RANKING DS1 - ESCOLHA DO CAMPE√ÉO
# Objetivo: Compara√ß√£o objetiva de m√©tricas para avan√ßar com o pipeline v2.
# ==============================================================================
# Mudamos a ordena√ß√£o para ROC-AUC, que √© o nosso crit√©rio de desempate realista
df_ranking = pd.DataFrame(resultados).sort_values(by='ROC-AUC', ascending=False)
display(df_ranking)

print("üìå PARECER T√âCNICO: Escolhemos o LightGBM com base no ROC-AUC superior.")
print("Justificativa: Como o F1-Score est√° zerado devido ao sinal fraco das features atuais,")
print("o ROC-AUC √© a m√©trica mais confi√°vel para medir o potencial de aprendizado do modelo.")

"""üèÜ Conclus√£o e Escolha do Modelo: DS1 - Semana 3
O que aprendemos com os testes?
No come√ßo dos nossos testes, os modelos estavam com nota 10 (100% de acerto), o que parecia √≥timo, mas descobrimos que era um erro t√©cnico chamado Vazamento de Dados (Data Leakage). O modelo estava "colando" na prova porque as colunas de atraso real estavam no treino.
‚Äã

Corrigimos isso e agora temos resultados reais. O F1-Score deu zero porque, apenas com as informa√ß√µes de hor√°rio e aeroporto, o problema de prever atrasos √© muito dif√≠cil e a base de dados tem poucos exemplos de voos atrasados. O modelo ainda √© cauteloso, mas o ROC-AUC de 0.66 mostra que ele j√° come√ßou a aprender padr√µes importantes.
‚Äã

Por que escolhemos o LightGBM?
Decidimos seguir com o modelo LightGBM para a pr√≥xima semana pelos seguintes motivos:

Melhor Potencial: Ele teve a maior nota no ROC-AUC (0.6640), o que prova que ele √© o mais "inteligente" do grupo para separar o que √© voo pontual do que √© atrasado.

"""