# ğŸ“˜ *Semana 05 â€” DocumentaÃ§Ã£o projeto de Data Science*
 
Nas semanas anteriores, o projeto avanÃ§ou de forma progressiva na construÃ§Ã£o do modelo e da API, passando pelas etapas de preparaÃ§Ã£o dos dados, anÃ¡lise exploratÃ³ria, 
desenvolvimento de features e treinamento de modelos de Machine Learning. Ao longo desse perÃ­odo, o principal esforÃ§o da equipe esteve concentrado em viabilizar um fluxo funcional de prediÃ§Ã£o, 
garantindo que o modelo pudesse ser treinado, avaliado e utilizado de forma integrada ao sistema. Esse trabalho tÃ©cnico estabeleceu a base necessÃ¡ria para que o projeto chegasse ao estÃ¡gio atual com uma soluÃ§Ã£o operacional.

Com a finalizaÃ§Ã£o das etapas tÃ©cnicas nas semanas anteriores, o projeto entra agora em uma fase diferente, cujo foco principal nÃ£o Ã© a criaÃ§Ã£o de novas funcionalidades, mas a organizaÃ§Ã£o, explicaÃ§Ã£o 
  e formalizaÃ§Ã£o do que jÃ¡ foi desenvolvido. Dessa forma agora precisamos estruturar a documentaÃ§Ã£o do projeto, transformando o trabalho tÃ©cnico realizado atÃ© aqui em material claro, compreensÃ­vel e bem organizado, 
      capaz de ser entendido tanto por avaliadores quanto por pessoas que nÃ£o participaram diretamente do desenvolvimento.

Nesta semana cada frente de trabalho foi definida com objetivos claros, tarefas bem delimitadas e perguntas-chave que orientam a escrita da documentaÃ§Ã£o, evitando improvisaÃ§Ãµes e garantindo que todos estejam trabalhando 
        a partir do mesmo entendimento do projeto. O objetivo Ã© assegurar consistÃªncia, qualidade e clareza em todas as entregas produzidas ao longo da semana.Ao final desta etapa, espera-se que o projeto conte com uma 
            documentaÃ§Ã£o estruturada que reflita de forma fiel as decisÃµes tomadas, as etapas executadas e as limitaÃ§Ãµes identificadas durante o desenvolvimento. 

---

## ğŸ› ï¸ *DS1 â€“ DOCUMENTAÃ‡ÃƒO DATASET & ETL*

### Objetivo

O objetivo desta frente Ã© documentar, de forma clara, progressiva e contextualizada, a origem dos dados utilizados no projeto e todas as etapas iniciais de preparaÃ§Ã£o desses dados atÃ© que estejam prontos para serem analisados e utilizados em um modelo de Machine Learning. Essa documentaÃ§Ã£o deve permitir que qualquer leitor, mesmo sem conhecimento prÃ©vio do projeto, compreenda de onde os dados vÃªm, qual fenÃ´meno real eles representam, como estÃ£o organizados e quais decisÃµes tÃ©cnicas foram tomadas durante o processo de extraÃ§Ã£o, transformaÃ§Ã£o e limpeza.

AlÃ©m disso, esta frente deve explicar como a variÃ¡vel alvo foi definida a partir dos dados brutos, deixando explÃ­citas as regras de negÃ³cio adotadas e as limitaÃ§Ãµes existentes jÃ¡ nessa etapa inicial do pipeline. O foco nÃ£o Ã© apenas descrever o que foi feito, mas justificar por que cada decisÃ£o foi necessÃ¡ria para garantir a qualidade e a consistÃªncia dos dados utilizados nas etapas seguintes do projeto.

---

### Tarefas

  * Ler cuidadosamente todas as cÃ©lulas iniciais do notebook atÃ© o final do ETL
  * Identificar a fonte pÃºblica do dataset
  * Entender a estrutura dos arquivos utilizados
  * Mapear todas as transformaÃ§Ãµes iniciais feitas nos dados
  * Identificar exatamente como o target foi definido

---

### Perguntas-chave (todas devem ser respondidas)
> **  - Qual Ã© a origem pÃºblica dos dados?
      - Qual problema real esses dados representam?
      - O que cada linha do dataset representa?
      - Quais arquivos sÃ£o carregados no projeto?
      - Quais colunas principais existem nos dados brutos?
      - Quais tratamentos iniciais sÃ£o aplicados (limpeza, conversÃ£o, filtros)?
      - Quais dados sÃ£o descartados e por quÃª?
      - Como a variÃ¡vel alvo â€œatrasadoâ€ Ã© definida?
      - Quais limitaÃ§Ãµes jÃ¡ existem nos dados antes da modelagem?**
---

### ğŸ”– EntregÃ¡veis
  * README explicativo 
  * Muito bem organizado
  * Linguagem tÃ©cnica e explicativa
  * Tudo deve ser rastreÃ¡vel ao notebook

---

## ğŸ§© *DS2 â€“ DOCUMENTAÃ‡ÃƒO EDA (AnÃ¡lise ExploratÃ³ria)*

### Objetivo da frente

O objetivo desta frente Ã© documentar o processo de anÃ¡lise exploratÃ³ria dos dados, explicando como os dados se comportam antes da modelagem e quais padrÃµes, tendÃªncias ou problemas puderam ser identificados a partir dessa anÃ¡lise. A documentaÃ§Ã£o deve mostrar que a EDA nÃ£o foi realizada de forma automÃ¡tica ou superficial, mas sim como uma etapa fundamental para entender o dataset, avaliar sua qualidade e orientar decisÃµes tÃ©cnicas posteriores.

Essa seÃ§Ã£o deve ajudar o leitor a compreender quais caracterÃ­sticas dos dados sÃ£o mais relevantes para o problema proposto, se existe desbalanceamento entre classes, se hÃ¡ padrÃµes temporais ou estruturais importantes e quais limitaÃ§Ãµes foram identificadas nessa fase. O objetivo final Ã© demonstrar que as decisÃµes tomadas no pipeline nÃ£o foram arbitrÃ¡rias, mas baseadas em observaÃ§Ãµes concretas obtidas durante a exploraÃ§Ã£o dos dados.

---

### Tarefas

  * Ler todas as cÃ©lulas de EDA do notebook
  * Entender o propÃ³sito de cada anÃ¡lise realizada
  * Identificar padrÃµes relevantes
  * Relacionar insights com decisÃµes do pipeline

---

### Pergunta-chave (todas devem ser respondidas)
> **  - Qual era o objetivo da EDA neste projeto?
      - Como estÃ¡ distribuÃ­da a variÃ¡vel alvo?
      - Existe desbalanceamento entre as classes?
      - Quais variÃ¡veis parecem mais relevantes?
      - Existem padrÃµes temporais importantes?
      - Algum comportamento inesperado foi identificado?
      - Como a EDA influenciou feature engineering ou modelagem?
      - Quais limitaÃ§Ãµes foram identificadas na fase exploratÃ³ria?
**

---

### ğŸ”– EntregÃ¡veis
  * README explicativo 
  * Muito bem organizado
  * Texto interpretativo
  * NÃ£o incluir prints de grÃ¡ficos
  * NÃ£o listar anÃ¡lises sem explicaÃ§Ã£o

---

## âš–ï¸ *DS3 â€“ DOCUMENTAÃ‡ÃƒO FEATURE ENGINEERING*

### Objetivo da frente

O objetivo desta frente Ã© explicar, de maneira detalhada e conceitualmente clara, como os dados brutos foram transformados em variÃ¡veis adequadas para treinamento do modelo de Machine Learning. Essa documentaÃ§Ã£o deve deixar evidente que o feature engineering nÃ£o consiste apenas em criar novas colunas, mas em um processo estruturado de transformaÃ§Ã£o, seleÃ§Ã£o e organizaÃ§Ã£o das informaÃ§Ãµes relevantes presentes nos dados originais.

Nesta frente, espera-se que o integrante demonstre entendimento sobre por que determinadas transformaÃ§Ãµes foram necessÃ¡rias para permitir que o modelo capture padrÃµes temporais, categÃ³ricos e estatÃ­sticos do problema estudado. A documentaÃ§Ã£o deve explicar como variÃ¡veis relacionadas a tempo, categorias e estatÃ­sticas agregadas foram construÃ­das, qual o papel de cada grupo de features dentro do pipeline e como essas transformaÃ§Ãµes contribuem para melhorar a capacidade preditiva do modelo.

AlÃ©m disso, esta seÃ§Ã£o deve evidenciar a preocupaÃ§Ã£o com boas prÃ¡ticas de Data Science, como a prevenÃ§Ã£o de data leakage e a manutenÃ§Ã£o de um pipeline reproduzÃ­vel, no qual todas as transformaÃ§Ãµes sÃ£o aplicadas de forma consistente tanto nos dados de treino quanto nos dados de inferÃªncia. O foco nÃ£o estÃ¡ em detalhar cÃ³digo, mas em mostrar compreensÃ£o do raciocÃ­nio tÃ©cnico por trÃ¡s das transformaÃ§Ãµes realizadas e reconhecer as limitaÃ§Ãµes do conjunto de features atual.
---

### Tarefas

  * Ler todas as cÃ©lulas de transformaÃ§Ã£o de dados
  * Identificar cada grupo de features criadas
  * Entender o papel de cada transformaÃ§Ã£o
  * Identificar estratÃ©gias de prevenÃ§Ã£o de data leakage.

---

### Pergunta-chave
> **  - Quais colunas entram no pipeline como dados brutos?
      - Quais transformaÃ§Ãµes temporais sÃ£o aplicadas?
      - Como variÃ¡veis categÃ³ricas sÃ£o tratadas?
      - Existem features agregadas? Com base em quÃª?
      - Como o pipeline evita vazamento de informaÃ§Ã£o?
      - Alguma feature foi descartada? Por quÃª?
      - Quais limitaÃ§Ãµes ainda existem nas features?**

---

### ğŸ”– EntregÃ¡veis
  * README explicativo 
  * Muito bem organizado
  * Texto interpretativo e tecnico
  * NÃ£o incluir cÃ³digo

---

## ğŸ§ª *DS4 â€“ DOCUMENTAÃ‡ÃƒO MODELAGEM & AVALIAÃ‡ÃƒO*

### Objetivo da frente

O objetivo desta frente Ã© documentar o processo de treinamento e avaliaÃ§Ã£o do modelo de Machine Learning de forma acessÃ­vel, coerente e alinhada ao contexto do problema. A documentaÃ§Ã£o deve permitir que um leitor sem formaÃ§Ã£o aprofundada em Machine Learning compreenda qual tipo de problema estÃ¡ sendo resolvido, como o modelo foi treinado e de que forma seu desempenho foi avaliado.

Essa frente deve explicar as escolhas realizadas em relaÃ§Ã£o ao tipo de modelo, Ã  estratÃ©gia de divisÃ£o dos dados e Ã s mÃ©tricas de avaliaÃ§Ã£o utilizadas, sempre relacionando essas decisÃµes ao objetivo do projeto. TambÃ©m Ã© fundamental que a documentaÃ§Ã£o apresente uma interpretaÃ§Ã£o clara dos resultados obtidos, destacando tanto os pontos fortes quanto as limitaÃ§Ãµes do modelo, demonstrando consciÃªncia crÃ­tica sobre sua aplicabilidade em um cenÃ¡rio real.
---

### Tarefas

  * Ler as cÃ©lulas de treino e validaÃ§Ã£o
  * Identificar modelo, mÃ©tricas e estratÃ©gia de split
  * Interpretar resultados obtidos

---

### Pergunta-chave
> **  - Qual Ã© o tipo de problema resolvido?
      - Qual modelo foi escolhido?
      - Como os dados foram divididos?
      - Por que essa estratÃ©gia de divisÃ£o foi usada?
      - Quais mÃ©tricas foram escolhidas?
      - O que os resultados indicam?
      - Quais sÃ£o as principais limitaÃ§Ãµes do modelo?
**

---

### ğŸ”– EntregÃ¡veis
  * README explicativo 
  * Muito bem organizado
  * Texto interpretativo e tecnico
  * Focar na interpretaÃ§Ã£o do modelo e nÃ£o na matemÃ¡tica

---

## ğŸ§ª *DS5 â€“ PIPELINE & SCRIPT PYTHON*

### Objetivo da frente

O objetivo desta frente Ã© documentar a estrutura lÃ³gica do projeto de Data Science como um todo, explicando o papel do script Python no suporte ao pipeline construÃ­do no notebook e sua importÃ¢ncia para a organizaÃ§Ã£o, reutilizaÃ§Ã£o e manutenÃ§Ã£o do cÃ³digo. Essa documentaÃ§Ã£o deve mostrar que o projeto nÃ£o se limita a um notebook isolado, mas que foi estruturado de forma modular, separando responsabilidades e centralizando funÃ§Ãµes crÃ­ticas em um arquivo especÃ­fico.

Nesta frente, o integrante deve explicar como o script Python agrupa funcionalidades relacionadas Ã  ingestÃ£o de dados, feature engineering, divisÃ£o de dados, treinamento de modelos e explicabilidade, e como essas funÃ§Ãµes sÃ£o utilizadas ao longo do notebook. O objetivo nÃ£o Ã© descrever cada funÃ§Ã£o linha a linha, mas fornecer uma visÃ£o arquitetural que ajude o leitor a entender como o pipeline foi pensado como um sistema integrado.

AlÃ©m disso, esta documentaÃ§Ã£o deve destacar como essa separaÃ§Ã£o contribui para reprodutibilidade, clareza do projeto e futura integraÃ§Ã£o com a API, bem como reconhecer as limitaÃ§Ãµes atuais dessa arquitetura e possÃ­veis caminhos de evoluÃ§Ã£o. Essa frente Ã© fundamental para demonstrar maturidade tÃ©cnica e organizaÃ§Ã£o do projeto aos avaliadores.
---

### Tarefas

  * Ler o script Python inteiro
  * Identificar os principais blocos funcionais
  * Relacionar cada bloco com etapas do notebook
  * Entender como o pipeline Ã© reutilizÃ¡vel

---

### Pergunta-chave
> **  - Qual Ã© o papel do script Python no projeto?
      - Por que separar lÃ³gica em um script externo?
      - Quais tipos de funÃ§Ãµes o script centraliza?
      - Como o script ajuda na organizaÃ§Ã£o do pipeline?
      - Como ele contribui para reprodutibilidade?
      - Como o notebook utiliza esse script?
      - O que o script nÃ£o faz (limitaÃ§Ãµes)?
      - O que poderia ser expandido no futuro?**

---

### ğŸ”– EntregÃ¡veis
  * README explicativo 
  * Muito bem organizado
  * Lingua contextual
  * Foco em arquitetura lÃ³gica

---
## Estrutura Final

docs/
 â”œâ”€ 01_etl.md
 â”œâ”€ 02_eda.md
 â”œâ”€ 03_feature_engineering.md
 â”œâ”€ 04_modelagem.md
 â””â”€ 05_pipeline_script.md

---

## ğŸ“… Cronograma da Semana 4 â€” Datas Importantes

### ğŸ—“ï¸ Segunda-feira â€” 12/01
**ReuniÃ£o de planejamento**
* Alinhamento das responsabilidades de cada integrante;  
* Esclarecimento de dÃºvidas tÃ©cnicas e definiÃ§Ã£o do escopo final.

### ğŸ—“ï¸ Quinta-feira â€” 15/01
**DemonstraÃ§Ã£o das entregas**
* Leitura e apresentaÃ§Ã£o dos arquivos desenvolvido por cada integrante.

### ğŸ—“ï¸ Sexta-feira â€” 09/01
**ConsolidaÃ§Ã£o final**
* RevisÃ£o do README e documentaÃ§Ã£o;  

---

## â„¹ï¸ ObservaÃ§Ã£o 
ReuniÃµes adicionais poderÃ£o ser marcadas ao longo da semana conforme a necessidade,
especialmente para alinhamentos tÃ©cnicos ou validaÃ§Ãµes de integraÃ§Ã£o.
